{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting svm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile svm.py\n",
    "#fetch newsgroupdata\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    \n",
    "    \n",
    "# evaluation code\n",
    "num_labels=19\n",
    "#industry=[i.rstrip(\"\\n\") for i in open(\"news//industry.wl\").readlines()]\n",
    "def fast_hist(a, b, n):\n",
    "    k = (a >= 0) & (a < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n**2).reshape(n, n)\n",
    "\n",
    "def evaluate(predict,label,num_labels=19,save_file=\"\"):\n",
    "    \n",
    "    predict=np.array(predict).astype(int)\n",
    "    label=np.array(label).astype(int)\n",
    "    confuse = fast_hist(predict,label,num_labels)\n",
    "    precision=np.diag(confuse)/np.sum(confuse,axis=1)\n",
    "    recall = np.diag(confuse)/np.sum(confuse,axis=0)\n",
    "    accuarcy = np.diag(confuse).sum() / confuse.sum()\n",
    "    aver_precision=np.nanmean(precision)\n",
    "    aver_recall = np.nanmean(recall)\n",
    "    #print(confuse.astype(int))\n",
    "    if save_file != \"\":\n",
    "        np.savetxt(save_file, confuse.astype(int), delimiter=',', fmt='%s')\n",
    "    print(\"Recall:\")\n",
    "    print(\"\\n\".join([category[i]+\"\\t\\t\"+str(recall[i]) for i in range(num_labels)]))\n",
    "    print(\"\\nPrecision:\")\n",
    "    print(\"\\n\".join([category[i]+\"\\t\\t\"+str(precision[i]) for i in range(num_labels)]))\n",
    "    #print([(category[i],precision[i]) for i in range(num_labels)])\n",
    "    print(\"\\nF-Score:\")\n",
    "    print(\"\\n\".join([category[i]+\"\\t\\t\"+str(2/(1/precision[i]+1/recall[i])) for i in range(num_labels)]))\n",
    "    print(aver_precision,aver_recall,accuarcy)\n",
    "    \n",
    "def pr_plot(predict,label,predict_prob,num_labels=19):\n",
    "    threshold = np.linspace(0,0.9,10)\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for th in threshold:\n",
    "        my_predict = np.copy(predict)\n",
    "        my_predict[predict_prob<th]=num_labels\n",
    "        confuse = fast_hist(my_predict,label,num_labels+1)\n",
    "        precision_th=np.diag(confuse)/np.sum(confuse,axis=1)\n",
    "        recall_th = np.diag(confuse)/np.sum(confuse,axis=0)\n",
    "        precision.append(np.nanmean(precision_th[:-1]))\n",
    "        recall.append(np.nanmean(recall_th[:-1]))\n",
    "    p, = plt.plot(threshold,precision,'b')\n",
    "    #plt.legend(\"precision\")\n",
    "    r, =plt.plot(threshold,recall,'r')\n",
    "    plt.legend([p,r],[\"precision\",\"recall\"])\n",
    "    plt.show()\n",
    "    plt.plot(precision,recall)\n",
    "    plt.show()\n",
    "    \n",
    "def load_data(input_file,industry_file,with_body=False):\n",
    "    global industry,category\n",
    "    global num_labels\n",
    "    industry = {x.rstrip(\"\\n\"):i for i,x in enumerate(open(industry_file,\"r\",encoding = \"utf-8\").readlines())}\n",
    "    category = [x.rstrip(\"\\n\") for x in open(industry_file,\"r\",encoding = \"utf-8\").readlines()]\n",
    "    num_labels = len(category)\n",
    "    \n",
    "    title = [x.split(\"\\t\")[0] for x in open(input_file,\"r\",encoding = \"utf-8\").readlines()]\n",
    "    label=[industry[x.split(\"\\t\")[1].rstrip(\"\\n\")] for x in open(input_file,\"r\",encoding = \"utf-8\").readlines()]\n",
    "    if with_body:\n",
    "        body = [x.split(\"\\t\")[2] for x in open(input_file,\"r\",encoding = \"utf-8\").readlines()]\n",
    "        doc = {'title':title,'body':body}\n",
    "        return doc,label\n",
    "    else:\n",
    "        return title,label\n",
    "        \n",
    "def load_data_newsgroup():\n",
    "    global doc,label,test_doc,test_label\n",
    "    global num_labels\n",
    "    global industry,category\n",
    "    #newsgroup dataset\n",
    "    twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "    twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "    doc = twenty_train.data\n",
    "    label = twenty_train.target\n",
    "\n",
    "    test_doc = twenty_test.data\n",
    "    test_label=twenty_test.target\n",
    "    \n",
    "    category = list(twenty_train.target_names)\n",
    "    num_labels=len(category)\n",
    "    return doc,label,test_doc,test_label\n",
    "    \n",
    "def val_predict(text_clf,val_file,result_file):\n",
    "    global val_doc\n",
    "    val_doc = [x.rstrip(\"\\n\") for x in open(val_file,\"r\",encoding='utf-8').readlines()]\n",
    "    val_predict=text_clf.predict(val_doc)\n",
    "    result = open(result_file,\"w\",encoding=\"utf-8\")\n",
    "    for i in val_predict:\n",
    "        print(category[i])\n",
    "        result.write(category[i]+\"\\n\")\n",
    "    result.close()\n",
    "    \n",
    "    \n",
    "def train(text_clf,title,label,label_num=num_labels):\n",
    "    print(\"Model Training ...\")\n",
    "    text_clf = text_clf.fit(title,label)\n",
    "    print(\"Model Training Finished.\")\n",
    "    \n",
    "def test(text_clf,test_title,test_label,label_num=num_labels):\n",
    "    predicted = text_clf.predict(test_title)\n",
    "    \n",
    "    print(np.mean(predicted == test_label))\n",
    "    evaluate(predicted,test_label,label_num)\n",
    "    try:\n",
    "        predicted_prob = text_clf.predict_proba(test_title)\n",
    "        predicted_prob = np.argmax(predicted_prob,axis=1)\n",
    "        pr_plot(predicted,predicted_prob,test_label,label_num)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def grid_search(text_clf_svm,parameter,doc,label):\n",
    "    gs_clf = GridSearchCV(text_clf_svm, parameter, n_jobs=-1)\n",
    "    \n",
    "    gs_clf = gs_clf.fit(doc, label)\n",
    "    \n",
    "    print(gs_clf.best_score_)\n",
    "    print(gs_clf.best_params_)\n",
    "    \n",
    "def val(gt,predict,industry,predict_prob= None):\n",
    "    industry ={x.rstrip(\"\\n\"):i for i,x in enumerate(open(industry,encoding = \"utf-8\").readlines())}\n",
    "    gt =[industry[x.rstrip(\"\\n\")] for x in open(gt,encoding = \"utf-8\").readlines()]\n",
    "    predict =[industry[y] if y in industry else len(industry) for y in [x.rstrip(\"\\n\").lower().replace(\" \",\"\")  for x in open(predict,encoding = \"utf-8\").readlines()]]\n",
    "    gt = np.array(gt)\n",
    "    predict = np.array(predict)\n",
    "    confuse = fast_hist(gt,predict,len(industry)+1)\n",
    "    evaluate(predict,gt,len(industry))\n",
    "    if predict_prob is not None:\n",
    "        prob =[float(x.rstrip(\"\\n\")) for x in open(predict_prob,encoding = \"utf-8\").readlines()]\n",
    "        pr_plot(predict,gt,prob,len(industry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [cntk-py35]",
   "language": "python",
   "name": "Python [cntk-py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
