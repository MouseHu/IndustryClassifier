{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_processor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_processor.py\n",
    "import re\n",
    "import numpy as np\n",
    "from cucco import Cucco\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "cucco = Cucco()\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "stop_word=[\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \n",
    "           \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \n",
    "           \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \n",
    "           \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \n",
    "           \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \n",
    "           \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \n",
    "           \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \n",
    "           \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \n",
    "           \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \n",
    "           \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \n",
    "           \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \n",
    "           \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\",\n",
    "           \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "           \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\",\n",
    "           \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \n",
    "           \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \n",
    "           \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \n",
    "           \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \n",
    "           \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\",\n",
    "           \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \n",
    "           \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\",\n",
    "           \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\",\n",
    "           \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\",\n",
    "           \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\",\n",
    "           \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\",\n",
    "           \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\",\n",
    "           \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\",\n",
    "           \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\",\n",
    "           \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "           \"yourselves\", \"the\"]\n",
    "\n",
    "\n",
    "pre_low =False\n",
    "pre_old = False\n",
    "pre_stop = True\n",
    "pre_random = False\n",
    "\n",
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = string.replace(\"  \",\" \")\n",
    "    return string.strip()\n",
    "def split(title):\n",
    "    if pre_low:\n",
    "        title = title.lower()\n",
    "    title=title.replace(u\"\\u2029\",\"\").replace(u'\\xa0', u' ')\n",
    "    title=title.replace(\"’\",\"'\")\n",
    "    title=title.replace(\"‘\",\"'\")\n",
    "\n",
    "    title=title.replace(\"'m'\",\" am\")\n",
    "    title=title.replace(\"'s\",\" is\")\n",
    "    title=title.replace(\"'re\",\" are\")\n",
    "    title=title.replace(\"'ll\",\" will\")\n",
    "    raw= clean_str(title).split(\" \")\n",
    "    if pre_stop:\n",
    "        return [x for x in raw if x.lower() not in stop_word]\n",
    "    else:\n",
    "        return raw\n",
    "def compose_random(word_list):\n",
    "    if len(word_list)==0:\n",
    "        print(\"hei!\")\n",
    "        return \"\"\n",
    "    my_list=copy.copy(word_list)\n",
    "    a=np.random.randint(4)\n",
    "    b=np.random.randint(len(word_list))\n",
    "    c=np.random.randint(len(word_list))\n",
    "    if a ==1:\n",
    "        del my_list[b]\n",
    "    if a == 2:\n",
    "        my_list.insert(b,'UNK')\n",
    "        #print(my_list)\n",
    "    if a == 3:\n",
    "        tmp=my_list[b]\n",
    "        my_list[b]=my_list[c]\n",
    "        my_list[c]=tmp\n",
    "    return compose(my_list)\n",
    "\n",
    "def compose(word_list):\n",
    "    return (\" \".join(word_list)).replace(u'\\xa0', u' ').strip(\" \")\n",
    "\n",
    "\n",
    "def process_new_cucco(title):\n",
    "    title = cucco.normalize(title)\n",
    "\n",
    "    \n",
    "    title = re.sub(r\"[0-9,]+[A-Z,a-z]\\s\", \"UNINUMBER \", title)\n",
    "    title = re.sub(r\"[0-9,]+\", \" UNINUMBER \", title)#\n",
    "    title = re.sub(r\"\\s\\s\", \" \", title)\n",
    "    \n",
    "    title = re.sub(r\"([^A-Z,a-z,\\\",'])\", r\" \\1 \", title)\n",
    "    \n",
    "    title = re.sub(r\"\\s\\s\", \" \", title)\n",
    "    title = re.sub(r\"\\s\\s\", \" \", title)\n",
    "    title = re.sub(r\"\\A\\s\", \"\", title)\n",
    "    title = re.sub(r\"\\s\\Z\", \"\", title)\n",
    "    title = [stem.stem(t) for t in title.split(\" \")]\n",
    "    return \" \".join(title)\n",
    "\n",
    "def process_new(sentence):\n",
    "    lemma = [wnl.lemmatize(t) for t in nltk.word_tokenize(sentence)]\n",
    "    return \" \".join(lemma)\n",
    "def process_property():\n",
    "    return {'low':pre_low,'old':pre_old,'stop':pre_stop}\n",
    "def process_setting(low =True,old = True,stop = True):\n",
    "    global pre_low,pre_old,pre_stop\n",
    "    pre_low=low\n",
    "    pre_old = old\n",
    "    pre_stop = stop\n",
    "def tokenize(title):\n",
    "    if pre_old:\n",
    "        if pre_random:\n",
    "            return compose_random(split(title))\n",
    "        else:\n",
    "            return compose(split(title))\n",
    "    else:\n",
    "        return process_new_cucco(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Youll wanna test knowledge power french beacon'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_processor import *\n",
    "process_new_cucco(\" You'll wanna test 'knowledge is power, french is beacon' .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(1, 7), match='18,000'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [cntk-py35]",
   "language": "python",
   "name": "Python [cntk-py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
