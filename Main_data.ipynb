{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_generator import *\n",
    "from data_processor import *\n",
    "from svm import *\n",
    "\n",
    "valid_industry = [\n",
    "    \"Non-profit & civil organization\",\"Finance\",\"Video game\",\"Media\",\"Health care & biotechnology\",\n",
    "    \"Entertainment \", \"food\",\"Information technology\",\"Education\",\"Government\",\"Airline\",\"Retail\",\n",
    "    \"Arts\",\"Manufacture \",\"Transportation\",\"Construction \",\"Automotive industry\",\"evergreen\",\"sports\"\n",
    "]\n",
    "black_list= [\n",
    "    \"entertainment\", \"government\", \"arts\", \"education\", \"transportation\", \"evergreen\"\n",
    "]\n",
    "valid_industry=[x.lower().replace(\" \",\"\") for x in valid_industry]\n",
    "#prefix = \"C:\\\\Users\\\\t-haohu\\\\Documents\\\\Python\\\\IndustryClassifier\\\\Data\"\n",
    "#prefix_ori = \"C:\\\\Users\\\\t-haohu\\\\Documents\\\\Python\\\\news\\\\Data\"\n",
    "prefix = \"/home/t-haohu/IndustryClassifier/Data\"\n",
    "prefix_ori = \"/home/t-haohu/IndustryClassifier/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#180days all\n",
    "\n",
    "\n",
    "#170days\n",
    "\n",
    "suffix = \"170days_again\"\n",
    "\n",
    "data_ori = \"{}\\\\raw\\\\ClassifierTrainingData-170days-180813.csv\".format(prefix_ori)\n",
    "data_raw = \"{}\\\\middle\\\\{}_raw.txt\".format(prefix,suffix)\n",
    "data_token = \"{}\\\\middle\\\\{}_tokenized.txt\".format(prefix,suffix)\n",
    "\n",
    "data_train = \"{}\\\\middle\\\\train_{}.txt\".format(prefix,suffix)\n",
    "data_test = \"{}\\\\middle\\\\test_{}.txt\".format(prefix,suffix)\n",
    "\n",
    "data_industry = \"{}\\\\ready\\\\industry_{}.wl\".format(prefix,suffix)\n",
    "data_vocabulary = \"{}\\\\ready\\\\title_{}.wl\".format(prefix,suffix)\n",
    "\n",
    "#extract_data(data_ori,data_raw,cols=[2,7],processor =[lambda x:x, lambda x:x.lower().replace(\" \",\"\")],\n",
    "#             criteria=(lambda row:row[7].lower().replace(\" \",\"\") in valid_industry))\n",
    "process_setting(low =False,old = False,stop = False)\n",
    "#tokenize_data(data_raw,data_token,[1],{0:lambda x:len(x.split(\" \"))<2})\n",
    "dict_list = dict_data(data_token,[1])\n",
    "dedup_data(data_token,data_token)\n",
    "dict2file(dict_list,[data_vocabulary,data_industry],criteria=[lambda x:x>5,lambda x:True])\n",
    "#shuffle_data(data_token)\n",
    "split_data(data_token,data_train,data_test,split_count  = 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\t-haohu\\\\Documents\\\\Python\\\\news\\\\Data\\\\raw\\\\ClassifierTrainingData-180days-180823.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b7a1f440befd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m extract_data(data_ori,data_raw,cols=[2,3,7],processor =[lambda x:x,lambda x:x, lambda x:x.lower().replace(\" \",\"\")],\n\u001b[0;32m---> 25\u001b[0;31m              criteria=(lambda row:row[7].lower().replace(\" \",\"\") in valid_industry))\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IndustryClassifier/data_generator.py\u001b[0m in \u001b[0;36mextract_data\u001b[0;34m(input_name, output_name, cols, processor, criteria, delimiter)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[0mdecide\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     '''\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf_8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf_8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\t-haohu\\\\Documents\\\\Python\\\\news\\\\Data\\\\raw\\\\ClassifierTrainingData-180days-180823.csv'"
     ]
    }
   ],
   "source": [
    "#180days sample & body\n",
    "\n",
    "\n",
    "suffix = \"180days_sample\"\n",
    "data_ori = \"{}\\\\raw\\\\ClassifierTrainingData-180days-180823.csv\".format(prefix_ori)\n",
    "data_raw = \"{}\\\\middle\\\\{}_raw_body.txt\".format(prefix,suffix)\n",
    "\n",
    "\n",
    "data_sample = \"{}\\\\middle\\\\sample_{}.txt\".format(prefix,suffix)\n",
    "data_sample_truncated = \"{}\\\\middle\\\\sample_{}_truncated.txt\".format(prefix,suffix)\n",
    "\n",
    "data_token = \"{}\\\\middle\\\\{}_token.txt\".format(prefix,suffix)\n",
    "data_train_sample = \"{}\\\\middle\\\\train_{}.txt\".format(prefix,suffix)\n",
    "data_test_sample = \"{}\\\\middle\\\\test_{}.txt\".format(prefix,suffix)\n",
    "\n",
    "data_token_body = \"{}\\\\middle\\\\{}_token_body.txt\".format(prefix,suffix)\n",
    "data_train_sample_body = \"{}\\\\middle\\\\train_{}_body.txt\".format(prefix,suffix)\n",
    "data_test_sample_body = \"{}\\\\middle\\\\test_{}_body.txt\".format(prefix,suffix)\n",
    "\n",
    "data_industry_sample = \"{}\\\\ready\\\\industry_{}.wl\".format(prefix,suffix)\n",
    "data_title_sample = \"{}\\\\ready\\\\title_{}.wl\".format(prefix,suffix)\n",
    "data_body_sample = \"{}\\\\ready\\\\body_{}.wl\".format(prefix,suffix)\n",
    "\n",
    "extract_data(data_ori,data_raw,cols=[2,3,7],processor =[lambda x:x,lambda x:x, lambda x:x.lower().replace(\" \",\"\")],\n",
    "             criteria=(lambda row:row[7].lower().replace(\" \",\"\") in valid_industry))\n",
    "\n",
    "sample_data(data_raw,data_sample,60000)\n",
    "\n",
    "extract_data(data_sample,data_sample_truncated,cols=[0,1,2],processor =[lambda x:x,lambda x:x.split(\"\\t\")[:200] if len(x.split(\"\\t\"))>200 else x,lambda x:x])\n",
    "\n",
    "tokenize_data(data_sample_truncated,data_token_body,no_token_list=[2],filters={0:lambda x: len(x.split(\" \"))<2,1:lambda x:len(x.split(\" \"))<2})\n",
    "\n",
    "dedup_data(data_token_body,data_token_body,selector = lambda row:row.split(\"\\t\")[0])\n",
    "\n",
    "dict_list = dict_data(data_token_body,[2])\n",
    "dict2file(dict_list,[data_title_sample,data_body_sample,data_industry_sample],criteria=[lambda x:x>2,lambda x:x>10,lambda x:True])\n",
    "\n",
    "extract_data(data_token_body,data_token,cols = [0,2],processor =[lambda x:x,lambda x:x])\n",
    "\n",
    "\n",
    "split_data(data_token,data_train_sample,data_test_sample)\n",
    "split_data(data_token_body,data_train_sample_body,data_test_sample_body)\n",
    "\n",
    "data_sample_body_ctf_train = \"{}\\\\ready\\\\train_{}_body.ctf\".format(prefix,suffix)\n",
    "data_sample_body_ctf_test = \"{}\\\\ready\\\\train_{}_body.ctf\".format(prefix,suffix)\n",
    "data_sample_ctf_train = \"{}\\\\ready\\\\train_{}.ctf\".format(prefix,suffix)\n",
    "data_sample_ctf_test = \"{}\\\\ready\\\\test_{}.ctf\".format(prefix,suffix)\n",
    "\n",
    "ctf_data(data_train_sample, data_sample_ctf_train, [data_title_sample,data_industry_sample])\n",
    "ctf_data(data_test_sample , data_sample_ctf_test , [data_title_sample,data_industry_sample])\n",
    "ctf_data(data_train_sample_body, data_sample_body_ctf_train, [data_title_sample,data_body_sample,data_industry_sample])\n",
    "ctf_data(data_test_sample_body , data_sample_body_ctf_test , [data_title_sample,data_body_sample,data_industry_sample])\n",
    "\n",
    "data_title_dict = \"{}\\\\ready\\\\title_{}.pkl\".format(prefix,suffix)\n",
    "data_body_dict = \"{}\\\\ready\\\\body_{}.pkl\".format(prefix,suffix)\n",
    "data_w2v_dict = \"{}\\\\raw\\\\GoogleNews-vectors-negative300.bin\".format(prefix_ori)\n",
    "embed_dict(data_w2v_dict,data_title_dict,dict_list[0])\n",
    "embed_dict(data_w2v_dict,data_body_dict,dict_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\t-haohu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "['HKEX', \"'needs\", 'patience', \"'\", 'to', 'develop', 'did', \"n't\", 'LME', 'business', 'with', 'mainland', 'China']\n",
      "['HKEX', \"'needs\", 'patience', \"'\", 'to', 'develop', 'did', \"n't\", 'LME', 'business', 'with', 'mainland', 'China']\n",
      "['hkex', \"'need\", 'patienc', \"'\", 'to', 'develop', 'did', \"n't\", 'lme', 'busi', 'with', 'mainland', 'china']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize\n",
    "#raw = \"ATLANTA — David Tepper comes from the Pittsburgh Steelers, where he was a minority owner for nine years. No one knows if he will try to craft the Carolina Panthers into a Steelers South. The Panthers had their own brand that they developed when previous owner Jerry Richardson was in charge for the last 23 years. Until Richardson blew it all up. Last December, Richardson was charged with sexual misconduct and using racist language in the workplace. Within hours, his team was for sale. Richardson’s son, Mark, wanted his father to sell the Panthers to Charleston businessman Ben Navarro. But the way Richardson and his son have butted heads over the years, Mark’s endorsement might well have been a death knell for Navarro. Or maybe, this is all that mattered: Tepper walked through the door worth $12 billion. He is paying $2.2 billion for the Panthers, in cash, except for $75 million that is being financed for tax purposes. Tepper instantly becomes the second-richest owner in the league behind Paul Allen’s nearly $20 billion. “He’s a good guy,” one NFL owner told me of Tepper, who made his fortune in hedgefunds. “He’s a very capable guy — with a lot of money.” Richardson and the other owners know the smell of money. They know green. Richardson missed an opportunity to move the minority number among this group of 32 NFL owners beyond one (Jacksonville’s Shad Khan). But it’s hard to argue with a cash deal to the guy with the most cash. But it won’t do Tepper much good as he toils in the cleanup of Richardson’s mess. Nobody talks about Richardson’s charges or his stupidity at this NFL spring league meeting. Shoot, they even gawked at a video tribute of his NFL life. They all celebrated his legacy — minus the dirt, of course. “It was a great recap of what it has meant for him to be in the NFL,” said Dallas Cowboys owner Jerry Jones, voice cracking, eyes misty. But Jones knows the power of a dollar. Especially $12 billion of them. He switched gears and emotions quickly when referencing Tepper: “David has a keen reputation for his business judgment. It’s a big win for the NFL and a great endorsement for its future. I want us to take advantage of his freshness. I want the league to use his freshness. To be able to attract someone with his talent and capital is a sign of a healthy sport.” The Panthers’ 2017 season was a spectacle after the Richardson revelations. At every turn, the players were asked about it. So were the coaches. They all looked at each other and wondered how the Richardson they knew could be so foul. But they finished 11-5 and second in the NFC West before losing a Wild Card playoff game, 31-26, at New Orleans. Tepper has a team, a franchise, a city with guts. Now he has to help mend it all, heal it, by addressing Richardson’s mistakes head on and creating policies within the building and relationships outside of it that build fibers of trust in both circles. He could walk through the door when he is expected to take over the team in July and fire them all, the coach Ron Rivera, general manager Marty Hurney, the front office staff, the support staff. Clean house. “I have a great appreciation for how stupid I am,” Tepper said. He was making it clear he will move prudently in all of those areas, get to know the people, the tasks, the makeup before making any changes. “He’s a good guy, he’s going to fit right in,” Khan said of Tepper. “I don’t know him; I shook his hand for the first time today,” Giants owner John Mara said. He shook the hands of a man who showed Richardson, who showed the NFL, the most money. He spoke their language — even glossier and with more floss than most of them. Tepper will find his place among this exclusive club. But more pressing, he must find his place in Carolina. And build a bridge from Richardson’s fractures to a David Tepper Carolina plan that everyone can buy. The final 10 seconds of Warriors vs. Rockets was completely bizarre What just happened? No idea, but it’s all tied up at two apiece now. James Harden’s poster dunk on Draymond Green left Chris Webber speechless We’ve got a new Dunk of the Year candidate, y’all. Rockets make it 2-2 after incredible game vs. Warriors It’s 2-2 in the Western Conference Finals after James Harden and the Rockets overcame a large deficit to win a close one in Game 4. The Rockets are the Warriors’ only real challenger, and they proved it Golden State hasn’t been tested in a couple years, and Houston’s here to do just that.\"\n",
    "raw = \"HKEX 'needs patience' to develop didn't LME business with mainland China\" \n",
    "tokens = word_tokenize(raw)\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "smg = [wnl.lemmatize(t) for t in tokens]\n",
    "stemmer = PorterStemmer()\n",
    "stm = [stemmer.stem(t) for t in smg]\n",
    "print(tokens)\n",
    "print(smg)\n",
    "print(stm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
