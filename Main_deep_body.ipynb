{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmodel_util import *\n",
    "from deepmodel_definition import *\n",
    "import deepmodel_util\n",
    "import deepmodel_definition\n",
    "\n",
    "deepmodel_definition.num_labels = 19#\n",
    "deepmodel_definition.emb_dim    = 300\n",
    "deepmodel_definition.hidden_dim = 200\n",
    "\n",
    "deepmodel_util.max_length_title = 30\n",
    "deepmodel_util.max_length_body  = 100\n",
    "deepmodel_definition.max_length_title = 30\n",
    "deepmodel_definition.max_length_body  = 100\n",
    "\n",
    "dropout_rate=0.5\n",
    "process_setting(low =False,old = True,stop = False)\n",
    "\n",
    "suffix = \"180days_all_body_shuffled\"\n",
    "prefix = \"/home/t-haohu/IndustryClassifier/Data/\"\n",
    "\n",
    "\n",
    "data_train_body = \"{}/middle/train_{}.txt\".format(prefix,suffix)\n",
    "data_test_body  = \"{}/middle/test_{}.txt\".format(prefix,suffix)\n",
    "\n",
    "\n",
    "data_title_vocab    = \"{}/ready/title_{}.wl\".format(prefix,suffix)\n",
    "data_body_vocab     = \"{}/ready/body_{}.wl\".format(prefix,suffix)\n",
    "data_industry_vocab = \"{}/ready/industry_{}.wl\".format(prefix,suffix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "title_dict =     { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_title_vocab).readlines()])}\n",
    "body_dict  =     { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_body_vocab ).readlines()])}\n",
    "industry_dict =  { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_industry_vocab).readlines()])}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "deepmodel_util.input_xt = C.input_variable(shape=(deepmodel_util.max_length_title),  dtype=np.float32)\n",
    "deepmodel_util.input_xb = C.input_variable(shape=(deepmodel_util.max_length_body) ,  dtype=np.float32)\n",
    "deepmodel_util.input_y  = C.input_variable(shape=(1)               ,  dtype=np.int)\n",
    "\n",
    "deepmodel_definition.input_xt_one_hot = C.one_hot(deepmodel_util.input_xt, num_classes=len(title_dict)   ,  sparse_output=True)\n",
    "deepmodel_definition.input_xb_one_hot = C.one_hot(deepmodel_util.input_xb, num_classes=len(body_dict)+1    ,  sparse_output=True) \n",
    "deepmodel_definition.input_y_one_hot = C.one_hot(deepmodel_util.input_y  , num_classes=len(industry_dict) ,  sparse_output=True)\n",
    "\n",
    "deepmodel_util.input_xt_one_hot = deepmodel_definition.input_xt_one_hot\n",
    "deepmodel_util.input_xb_one_hot = deepmodel_definition.input_xb_one_hot\n",
    "deepmodel_util.input_y_one_hot = deepmodel_definition.input_y_one_hot\n",
    "\n",
    "deepmodel_util.test_data  = load_data_body(data_test_body,title_dict,body_dict,industry_dict)\n",
    "deepmodel_util.train_data = load_data_body(data_train_body,title_dict,body_dict,industry_dict)\n",
    "\n",
    "\n",
    "\n",
    "#embedding_title = load_embedding(data_title_vocab,\"word2vec_title.model\")\n",
    "#embedding_body = load_embedding(data_body_vocab,\"word2vec_body.model\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Output('classify', [#], [19]), Output('Splice695_Output_0', [#], [300 x 1 x 1]), Output('pooling_t_1', [#], [50 x 1 x 1]), Output('Block174_Output_0', [#], [50 x 29 x 1]), Output('embed', [#], [30 x 300]), Output('OneHotOp6_Output_0', [#], [30 x 56957]), Output('pooling_t_2', [#], [50 x 1 x 1]), Output('Block111_Output_0', [#], [50 x 30 x 1]), Output('pooling_t_3', [#], [50 x 1 x 1]), Output('Block237_Output_0', [#], [50 x 28 x 1]), Output('pooling_b_1', [#], [50 x 1 x 1]), Output('Block363_Output_0', [#], [50 x 99 x 1]), Output('embed', [#], [100 x 300]), Output('OneHotOp9_Output_0', [#], [100 x 216867]), Output('pooling_b_2', [#], [50 x 1 x 1]), Output('Block300_Output_0', [#], [50 x 100 x 1]), Output('pooling_b_3', [#], [50 x 1 x 1]), Output('Block426_Output_0', [#], [50 x 98 x 1])]\n",
      "data_size:  794568 batch_size:  30 num_batches_per_epoch:  26486\n",
      "Learning rate per minibatch: 0.015\n",
      "1000 34.09126019477844\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CNTK Function expected 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dde30f1b636f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_model_cnn_with_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepmodel_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rcnn_body\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/IndustryClassifier/deepmodel_util.py\u001b[0m in \u001b[0;36mtrain_body\u001b[0;34m(model, train_data, num_epochs, learning_rate, batch_size, l2_weight, tag, show_count, do_test)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdo_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0macc1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/{}_acc{:.3f}.dnn'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IndustryClassifier/deepmodel_util.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(batch_size, model, data)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_xt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mconfuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/ops/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# parse argument list and map to the function's input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0marg_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margument_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# if placeholders were excluded due to being under construction,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/ops/functions.py\u001b[0m in \u001b[0;36margument_map\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m    \u001b[0;31m# function parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNTK Function expected {} arguments, got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_function_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: CNTK Function expected 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "train_body(create_model_cnn_with_body(),deepmodel_util.train_data,num_epochs=20,learning_rate=[5e-4*30]*2+[1e-4*30],batch_size = 30,tag = \"rcnn_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_body(create_model_rcnn_body(),deepmodel_util.train_data,num_epochs=20,learning_rate=[5e-4*30]*2+[1e-4*30],batch_size = 30,tag = \"rcnn_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size:  361 batch_size:  30 num_batches_per_epoch:  13\n",
      "Precision:0.5033521453952122 Recall:0.6820123936735778 Acc:0.4515235457063712\n",
      "OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t-haohu/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/ipykernel_launcher.py:223: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "#test code \n",
    "#run the first cell first to load dict\n",
    "from cntk import load_model\n",
    "\n",
    "suffix = \"180days_all_body_shuffled\"\n",
    "prefix = \"/home/t-haohu/IndustryClassifier/Data/\"\n",
    "\n",
    "\n",
    "data_title_vocab    = \"{}/ready/title_{}.wl\".format(prefix,suffix)\n",
    "data_body_vocab     = \"{}/ready/body_{}.wl\".format(prefix,suffix)\n",
    "data_industry_vocab = \"{}/ready/industry_{}.wl\".format(prefix,suffix)\n",
    "\n",
    "title_dict =     { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_title_vocab).readlines()])}\n",
    "body_dict  =     { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_body_vocab ).readlines()])}\n",
    "industry_dict =  { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_industry_vocab).readlines()])}\n",
    "\n",
    "model = load_model(\"model/180days_all_body_shuffled/rcnn_body_acc0.871.dnn\")\n",
    "data_test_body = \"1day_sample_gt_body.txt\"\n",
    "test_data  = load_data_body(data_test_body,title_dict,body_dict,industry_dict,raw=True)\n",
    "test_body(30,model,test_data)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/t-haohu/IndustryClassifier/Data//ready/body_180days_all_shuffled.wl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8309abec3066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtitle_dict\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0;34m{\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_title_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbody_dict\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0;34m{\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_body_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0minference_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Data/middle/1day_measure_sample_valid.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"val/dyn_cnn_1day_measure_{}.txt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbody_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_industry_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/t-haohu/IndustryClassifier/Data//ready/body_180days_all_shuffled.wl'"
     ]
    }
   ],
   "source": [
    "#predict code\n",
    "from cntk import load_model\n",
    "from data_processor import *\n",
    "process_setting(low=False,old = True,stop = False)\n",
    "deepmodel_util.batch_size = 20\n",
    "#deepmodel_util.input_xt = C.input_variable(**Sequence[Tensor[1]])\n",
    "    \n",
    "model_file =\"model/180days_all_body_shuffled/cnn_body_acc0.867.dnn\"\n",
    "suffix_file = \"180days_all_shuffled\"\n",
    "industry_file = \"180days_all_shuffled\"\n",
    "\n",
    "model = load_model(model_file)\n",
    "\n",
    "data_industry_vocab = \"{}/ready/industry_{}.wl\".format(prefix,industry_file)\n",
    "data_title_vocab    = \"{}/ready/title_{}.wl\".format(prefix,suffix_file)\n",
    "data_body_vocab     = \"{}/ready/body_{}.wl\".format(prefix,suffix_file)\n",
    "\n",
    "title_dict =     { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_title_vocab).readlines()])}\n",
    "body_dict =     { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_body_vocab).readlines()])}\n",
    "\n",
    "inference_body(model,\"Data/middle/1day_measure_sample_valid.txt\",\"val/dyn_cnn_1day_measure_{}.txt\".format(suffix),title_dict,body_dict,data_industry_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
