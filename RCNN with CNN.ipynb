{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import time \n",
    "\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "from cntk.layers import *\n",
    "from cntk.layers.typing import *\n",
    "import pickle\n",
    "import random\n",
    "from cntk import sequence\n",
    "from cntk import load_model\n",
    "from cntk.device import try_set_default_device, gpu,cpu\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "try_set_default_device(gpu(0))\n",
    "\n",
    "\n",
    "vocab_size = 80000\n",
    "num_labels = 19#19\n",
    "title_size = 52000\n",
    "body_size  = 210000\n",
    "input_dim  = vocab_size\n",
    "label_dim  = num_labels\n",
    "emb_dim    = 300\n",
    "hidden_dim = 200\n",
    "\n",
    "max_length_title = 53\n",
    "max_length_body  = 200\n",
    "\n",
    "suffix = \"180days_all_shuffled\"\n",
    "#suffix = \"linkedin_only\"\n",
    "prefix = \"/home/t-haohu/IndustryClassifier/Data/\"\n",
    "\n",
    "#data_token_body        = \"{}/middle/{}_token_body.txt\".format(prefix,suffix)\n",
    "data_train_sample = \"{}/middle/train_{}.txt\".format(prefix,suffix)\n",
    "#data_train_sample = \"{}/middle/train_{}_with_linkedin_all.txt\".format(prefix,suffix)\n",
    "data_test_sample  = \"{}/middle/test_{}.txt\".format(prefix,suffix)\n",
    "#data_test_sample_editor  = \"{}/middle/test_{}_editor.txt\".format(prefix,suffix)\n",
    "\n",
    "data_title_sample    = \"{}/ready/title_{}.wl\".format(prefix,suffix)\n",
    "data_body_sample     = \"{}/ready/body_{}.wl\".format(prefix,suffix)\n",
    "suffix = \"180days_all_shuffled\"\n",
    "data_industry_sample = \"{}/ready/industry_{}.wl\".format(prefix,suffix)\n",
    "filter_num=200 \n",
    "dropout_rate = 0.5\n",
    "emb_dim =300\n",
    "\n",
    "def load_data(input_file,title_dict,industry_dict):\n",
    "    data = open(input_file, encoding = \"utf-8\").readlines()\n",
    "    \n",
    "    data_title =np.zeros((len(data),max_length_title),dtype = np.float32)\n",
    "    data_label = np.zeros((len(data),1),dtype = np.float32)\n",
    "       \n",
    "    for index,line in enumerate(data):\n",
    "        row = line.strip(\"\\n\").split(\"\\t\")       \n",
    "        title    =  row[0]\n",
    "        industry =  row[1]\n",
    "        \n",
    "        for jndex,token in enumerate(title.split(\" \")):\n",
    "            if jndex>=max_length_title:\n",
    "                break\n",
    "            data_title[index,jndex]=title_dict.get(token,len(title_dict)-1)    \n",
    "        data_label[index] = industry_dict.get(industry,len(industry_dict))\n",
    "    return data_title,data_label\n",
    "\n",
    "\n",
    "def load_embedding(title_file,embedding_model_file):\n",
    "    model = Word2Vec.load(embedding_model_file)\n",
    "    title_list = [x.strip(\"\\n\") for x in open(title_file,encoding = 'utf-8').readlines()]\n",
    "    embedding = np.zeros((len(title_list),emb_dim))\n",
    "    count = 0\n",
    "    for i,w in enumerate(title_list):\n",
    "        try:\n",
    "            vec = model.wv[w]\n",
    "        except:\n",
    "            vec=model.wv[\"UNK\"]\n",
    "            count+=1\n",
    "        embedding[i] =vec\n",
    "    print(count)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "def get_context_left(current,previous,w_l,w_ls):\n",
    "    left_c = current@w_l\n",
    "    left_e = previous@w_ls\n",
    "    left_h=left_c+left_e\n",
    "    return C.relu(left_h)\n",
    "def get_context_right(current,after,w_r,w_rs):\n",
    "    right_c = current@w_r\n",
    "    right_e = after@w_rs\n",
    "    right_h =right_c+right_e\n",
    "    return C.relu(right_h)\n",
    "\n",
    "def create_model_rcnn(embed = False):\n",
    "    first_word = C.parameter(shape=(emb_dim))\n",
    "    last_word = C.parameter(shape=(emb_dim))\n",
    "    w_l,w_ls,w_r,w_rs = C.parameter(shape=(emb_dim,emb_dim)),C.parameter(shape=(emb_dim,emb_dim)),C.parameter(shape=(emb_dim,emb_dim)),C.parameter(shape=(emb_dim,emb_dim))\n",
    "    #version 2 : 1 dense layer version3: sigmoid activation in dense\n",
    "    if embed:\n",
    "        h1= C.layers.Embedding(weights=embedding,name='embed_1')(input_xt_one_hot)#\n",
    "    else:\n",
    "        h1= C.layers.Embedding(emb_dim,name='embed_2')(input_xt_one_hot)#init=embedding,\n",
    "    previous = first_word\n",
    "    # h1 [batch*sentence_length*emb_dim]\n",
    "    context_left_list = []\n",
    "    for i in range(max_length_title):\n",
    "        current = C.squeeze(h1[i])\n",
    "        context_left_list.append(get_context_left(current,previous,w_l,w_ls))\n",
    "        previous = current\n",
    "        \n",
    "    context_right_list = []\n",
    "    after = last_word\n",
    "    for i in reversed(range(max_length_title)):\n",
    "        current = C.squeeze(h1[i])\n",
    "        context_right_list.append(get_context_right(current,after,w_r,w_rs))\n",
    "        after = current\n",
    "    total_list = []\n",
    "    for i in range(max_length_title):\n",
    "        total_list.append(C.splice(h1[i],context_left_list[i],context_right_list[i]))\n",
    "    #output = C.splice(total_list)\n",
    "    #print(output)\n",
    "    #h2=BiRecurrence(C.layers.LSTM(hidden_dim), C.layers.LSTM(hidden_dim))(h1)\n",
    "    h3=C.element_max(*total_list)\n",
    "    print(h3)\n",
    "    drop1 = C.layers.Dropout(dropout_rate)(h3)\n",
    "    h4=C.layers.Dense(num_labels,name='hidden')(drop1)\n",
    "\n",
    "    return h4\n",
    "\n",
    "def create_model_cnn(embed = False):\n",
    "    #version 2 : 1 dense layer version3: sigmoid activation in dense\n",
    "    if embed:\n",
    "        h1= C.layers.Embedding(weights=embedding,name='embed_1')(input_xt_one_hot)#\n",
    "    else:\n",
    "        h1= C.layers.Embedding(emb_dim,name='embed_2')(input_xt_one_hot)#init=embedding,\n",
    "\n",
    "    \n",
    "\n",
    "    h2_1=C.layers.Convolution((2,emb_dim),num_filters=filter_num,reduction_rank=0,activation=C.relu)(h1)\n",
    "    h2_2=C.layers.Convolution((3,emb_dim),num_filters=filter_num,reduction_rank=0,activation=C.relu)(h1)\n",
    "    h2_3=C.layers.Convolution((4,emb_dim),num_filters=filter_num,reduction_rank=0,activation=C.relu)(h1)\n",
    "    \n",
    "    h3_1=C.layers.MaxPooling((max_length_title-1,1),name='pooling_1')(h2_1)\n",
    "    h3_2=C.layers.MaxPooling((max_length_title-2,1),name='pooling_2')(h2_2)\n",
    "    h3_3=C.layers.MaxPooling((max_length_title-3,1),name='pooling_3')(h2_3)\n",
    "    #h2=BiRecurrence(C.layers.LSTM(hidden_dim), C.layers.LSTM(hidden_dim))(h1)\n",
    "    h3=C.splice(h3_2,h3_1,h3_3,axis=0)\n",
    "    drop1 = C.layers.Dropout(dropout_rate)(h3)\n",
    "    h4=C.layers.Dense(num_labels,name='hidden')(drop1)\n",
    "\n",
    "    return h4\n",
    "def create_model_rcnn_with_cnn():\n",
    "    logit1 = create_model_cnn()\n",
    "    logit2 = create_model_rcnn()\n",
    "    weight1 = C.parameter(shape=(1),init=0.5)\n",
    "    weight2 = 1-weight1\n",
    "    logit = weight1*logit1+weight2*logit2\n",
    "    return logit \n",
    "\n",
    "def batch_iter(data,batch_size, num_epochs, shuffle=True):\n",
    "    # Generates a batch iterator for a dataset.\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((data_size-1)/batch_size) + 1\n",
    "    print('data_size: ', data_size, 'batch_size: ', batch_size, 'num_batches_per_epoch: ', num_batches_per_epoch)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            random.shuffle(data)\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield data[start_index:end_index]\n",
    "            \n",
    "\n",
    "def fast_hist(a, b, n):\n",
    "    k = (a >= 0) & (a < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n**2).reshape(n, n)\n",
    "\n",
    "title_dict =     { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_title_sample).readlines()])}\n",
    "industry_dict =  { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_industry_sample).readlines()])}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_xt = C.input_variable(shape=(max_length_title),  dtype=np.float32)\n",
    "#input_xt = C.input_variable(**Sequence[Tensor[1]])\n",
    "input_y  = C.input_variable(shape=(1)               ,  dtype=np.int)\n",
    "\n",
    "input_xt_one_hot = C.one_hot(input_xt, num_classes=len(title_dict)   ,  sparse_output=True)\n",
    "input_y_one_hot = C.one_hot(input_y  , num_classes=len(industry_dict) ,  sparse_output=True)\n",
    "\n",
    "\n",
    "test_data  = load_data(data_test_sample,title_dict,industry_dict)\n",
    "train_data = load_data(data_train_sample,title_dict,industry_dict)\n",
    "#test_data_editor  = load_data(data_test_sample_editor,title_dict,industry_dict)\n",
    "embedding = load_embedding(data_title_sample,\"word2vec.model\")\n",
    "\n",
    "def test(batch_size,model,data):\n",
    "    scores = model(input_xt)\n",
    "    predict = C.argmax(scores,axis = 0)\n",
    "    confuse = np.zeros((num_labels,num_labels))\n",
    "\n",
    "    test_data_title,test_data_label = data\n",
    "    batches = batch_iter(list(zip(test_data_title,test_data_label)), batch_size, 1)\n",
    "    \n",
    "    for batch in batches:\n",
    "        batch_data_title,batch_data_label = zip(*batch) \n",
    "        output = np.array(predict.eval({input_xt: np.array(batch_data_title)}),dtype=np.int)\n",
    "        gt = np.array(batch_data_label,dtype=np.int)\n",
    "        confuse+=fast_hist(output,gt,num_labels)\n",
    "        \n",
    "    precision=np.diag(confuse)/np.sum(confuse,axis=0)\n",
    "    recall = np.diag(confuse)/np.sum(confuse,axis=1)\n",
    "    accuarcy = np.diag(confuse).sum() / confuse.sum()\n",
    "    aver_precision=np.nanmean(precision)\n",
    "    aver_recall = np.nanmean(recall)\n",
    "   \n",
    "    print(\"Precision:{} Recall:{} Acc:{}\".format(aver_precision,aver_recall,accuarcy))\n",
    "    return accuarcy\n",
    "def train(train_data,num_epochs,learning_rate,batch_size,tag=\"CNN\",l2_weight=0):\n",
    "    global model\n",
    "    #learning_rate *= batch_size\n",
    "    model = create_model_rcnn_with_cnn()\n",
    "    print(C.logging.get_node_outputs(model))\n",
    "    scores = model(input_xt)\n",
    "\n",
    "    loss =C.reduce_mean(C.losses.cross_entropy_with_softmax(scores, input_y_one_hot))\n",
    "    \n",
    "    # Training\n",
    "    lr_schedule = C.learning_parameter_schedule(learning_rate)\n",
    "    #learner = C.adam(scores.parameters, lr=lr_schedule, momentum=0.9,l2_regularization_weight=0)\n",
    "    progress_printer = C.logging.ProgressPrinter(tag='Training', num_epochs=num_epochs)\n",
    "    momentums = C.momentum_schedule(0.99, minibatch_size=batch_size)\n",
    "    learner = C.adam(parameters=scores.parameters,#model.parameters,\n",
    "                     lr=lr_schedule,\n",
    "                     momentum=momentums,\n",
    "                     gradient_clipping_threshold_per_sample=15,\n",
    "                     gradient_clipping_with_truncation=True,\n",
    "                     l2_regularization_weight=l2_weight)\n",
    "    trainer = C.Trainer(scores, (loss), [learner], progress_printer)\n",
    "    \n",
    "    train_data_title,train_data_label = train_data\n",
    "    batches = batch_iter(list(zip(train_data_title,train_data_label)), batch_size, num_epochs)\n",
    "\n",
    "    # training loop\n",
    "    count = 0\n",
    "    t = time.time()\n",
    "    for batch in batches:\n",
    "        count += 1\n",
    "        batch_data_title,batch_data_label = zip(*batch)\n",
    "        batch_data_title = list(batch_data_title)\n",
    "        #print(type(batch_data_title),type(batch_data_title[0]),batch_data_title[0])\n",
    "        trainer.train_minibatch({input_xt: np.array(batch_data_title), input_y: np.array(batch_data_label)})\n",
    "        if count%1000== 0:\n",
    "            print(count,time.time()-t)\n",
    "            t=time.time()\n",
    "            acc1=test(batch_size,model,test_data)\n",
    "            #acc2=test(batch_size,model,test_data_editor)\n",
    "            \n",
    "            # save model\n",
    "            #model.save('./model/{}/{}_acc{:.3f}.dnn'.format(suffix,tag,acc1))\n",
    "            #model.save('./model/{}/{}_acc1{:.3f}_acc2{:.3f}.dnn'.format(suffix,tag,acc1,acc2))\n",
    "    \n",
    "\n",
    "    # save model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite(Tensor[53]) -> Tensor[1,900]\n",
      "[Output('Plus6121_Output_0', [#], [19]), Output('ElementTimes6115_Output_0', [#], [19]), Output('hidden', [#], [19]), Output('Block371_Output_0', [#], [600 x 1 x 1]), Output('Splice351_Output_0', [#], [600 x 1 x 1]), Output('pooling_2', [#], [200 x 1 x 1]), Output('Block142_Output_0', [#], [200 x 51 x 1]), Output('embed_2', [#], [53 x 300]), Output('OneHotOp5_Output_0', [#], [53 x 56178]), Output('pooling_1', [#], [200 x 1 x 1]), Output('Block79_Output_0', [#], [200 x 52 x 1]), Output('pooling_3', [#], [200 x 1 x 1]), Output('Block205_Output_0', [#], [200 x 50 x 1]), Output('ElementTimes6118_Output_0', [#], [19]), Output('Minus6112_Output_0', [], [1]), Output('hidden', [#], [19]), Output('Block3628_Output_0', [#], [1 x 900]), Output('Block3603_Output_0', [#], [1 x 900]), Output('Block3171_Output_0', [#], [1 x 900]), Output('Block2963_Output_0', [#], [1 x 900]), Output('Block2851_Output_0', [#], [1 x 900]), Output('Block2803_Output_0', [#], [1 x 900]), Output('Splice2464_Output_0', [#], [1 x 900]), Output('Slice2461_Output_0', [#], [1 x 300]), Output('embed_2', [#], [53 x 300]), Output('ReLU568_Output_0', [#], [300]), Output('Plus565_Output_0', [#], [300]), Output('Times559_Output_0', [#], [300]), Output('Squeeze556_Output_0', [#], [300]), Output('Slice553_Output_0', [#], [1 x 300]), Output('Times562_Output_0', [], [300]), Output('ReLU1522_Output_0', [#], [300]), Output('Plus1519_Output_0', [#], [300]), Output('Times1513_Output_0', [#], [300]), Output('Squeeze1510_Output_0', [#], [300]), Output('Slice1507_Output_0', [#], [1 x 300]), Output('Times1516_Output_0', [], [300]), Output('Block2787_Output_0', [#], [1 x 900]), Output('Splice2470_Output_0', [#], [1 x 900]), Output('Slice2467_Output_0', [#], [1 x 300]), Output('ReLU586_Output_0', [#], [300]), Output('Plus583_Output_0', [#], [300]), Output('Times577_Output_0', [#], [300]), Output('Squeeze574_Output_0', [#], [300]), Output('Slice571_Output_0', [#], [1 x 300]), Output('Times580_Output_0', [#], [300]), Output('ReLU1540_Output_0', [#], [300]), Output('Plus1537_Output_0', [#], [300]), Output('Times1531_Output_0', [#], [300]), Output('Squeeze1528_Output_0', [#], [300]), Output('Slice1525_Output_0', [#], [1 x 300]), Output('Times1534_Output_0', [#], [300]), Output('Splice2476_Output_0', [#], [1 x 900]), Output('Slice2473_Output_0', [#], [1 x 300]), Output('ReLU604_Output_0', [#], [300]), Output('Plus601_Output_0', [#], [300]), Output('Times595_Output_0', [#], [300]), Output('Squeeze592_Output_0', [#], [300]), Output('Slice589_Output_0', [#], [1 x 300]), Output('Times598_Output_0', [#], [300]), Output('ReLU1558_Output_0', [#], [300]), Output('Plus1555_Output_0', [#], [300]), Output('Times1549_Output_0', [#], [300]), Output('Squeeze1546_Output_0', [#], [300]), Output('Slice1543_Output_0', [#], [1 x 300]), Output('Times1552_Output_0', [#], [300]), Output('Block2835_Output_0', [#], [1 x 900]), Output('Splice2482_Output_0', [#], [1 x 900]), Output('Slice2479_Output_0', [#], [1 x 300]), Output('ReLU622_Output_0', [#], [300]), Output('Plus619_Output_0', [#], [300]), Output('Times613_Output_0', [#], [300]), Output('Squeeze610_Output_0', [#], [300]), Output('Slice607_Output_0', [#], [1 x 300]), Output('Times616_Output_0', [#], [300]), Output('ReLU1576_Output_0', [#], [300]), Output('Plus1573_Output_0', [#], [300]), Output('Times1567_Output_0', [#], [300]), Output('Squeeze1564_Output_0', [#], [300]), Output('Slice1561_Output_0', [#], [1 x 300]), Output('Times1570_Output_0', [#], [300]), Output('Block2819_Output_0', [#], [1 x 900]), Output('Splice2488_Output_0', [#], [1 x 900]), Output('Slice2485_Output_0', [#], [1 x 300]), Output('ReLU640_Output_0', [#], [300]), Output('Plus637_Output_0', [#], [300]), Output('Times631_Output_0', [#], [300]), Output('Squeeze628_Output_0', [#], [300]), Output('Slice625_Output_0', [#], [1 x 300]), Output('Times634_Output_0', [#], [300]), Output('ReLU1594_Output_0', [#], [300]), Output('Plus1591_Output_0', [#], [300]), Output('Times1585_Output_0', [#], [300]), Output('Squeeze1582_Output_0', [#], [300]), Output('Slice1579_Output_0', [#], [1 x 300]), Output('Times1588_Output_0', [#], [300]), Output('Splice2494_Output_0', [#], [1 x 900]), Output('Slice2491_Output_0', [#], [1 x 300]), Output('ReLU658_Output_0', [#], [300]), Output('Plus655_Output_0', [#], [300]), Output('Times649_Output_0', [#], [300]), Output('Squeeze646_Output_0', [#], [300]), Output('Slice643_Output_0', [#], [1 x 300]), Output('Times652_Output_0', [#], [300]), Output('ReLU1612_Output_0', [#], [300]), Output('Plus1609_Output_0', [#], [300]), Output('Times1603_Output_0', [#], [300]), Output('Squeeze1600_Output_0', [#], [300]), Output('Slice1597_Output_0', [#], [1 x 300]), Output('Times1606_Output_0', [#], [300]), Output('Block2947_Output_0', [#], [1 x 900]), Output('Block2883_Output_0', [#], [1 x 900]), Output('Splice2500_Output_0', [#], [1 x 900]), Output('Slice2497_Output_0', [#], [1 x 300]), Output('ReLU676_Output_0', [#], [300]), Output('Plus673_Output_0', [#], [300]), Output('Times667_Output_0', [#], [300]), Output('Squeeze664_Output_0', [#], [300]), Output('Slice661_Output_0', [#], [1 x 300]), Output('Times670_Output_0', [#], [300]), Output('ReLU1630_Output_0', [#], [300]), Output('Plus1627_Output_0', [#], [300]), Output('Times1621_Output_0', [#], [300]), Output('Squeeze1618_Output_0', [#], [300]), Output('Slice1615_Output_0', [#], [1 x 300]), Output('Times1624_Output_0', [#], [300]), Output('Block2867_Output_0', [#], [1 x 900]), Output('Splice2506_Output_0', [#], [1 x 900]), Output('Slice2503_Output_0', [#], [1 x 300]), Output('ReLU694_Output_0', [#], [300]), Output('Plus691_Output_0', [#], [300]), Output('Times685_Output_0', [#], [300]), Output('Squeeze682_Output_0', [#], [300]), Output('Slice679_Output_0', [#], [1 x 300]), Output('Times688_Output_0', [#], [300]), Output('ReLU1648_Output_0', [#], [300]), Output('Plus1645_Output_0', [#], [300]), Output('Times1639_Output_0', [#], [300]), Output('Squeeze1636_Output_0', [#], [300]), Output('Slice1633_Output_0', [#], [1 x 300]), Output('Times1642_Output_0', [#], [300]), Output('Splice2512_Output_0', [#], [1 x 900]), Output('Slice2509_Output_0', [#], [1 x 300]), Output('ReLU712_Output_0', [#], [300]), Output('Plus709_Output_0', [#], [300]), Output('Times703_Output_0', [#], [300]), Output('Squeeze700_Output_0', [#], [300]), Output('Slice697_Output_0', [#], [1 x 300]), Output('Times706_Output_0', [#], [300]), Output('ReLU1666_Output_0', [#], [300]), Output('Plus1663_Output_0', [#], [300]), Output('Times1657_Output_0', [#], [300]), Output('Squeeze1654_Output_0', [#], [300]), Output('Slice1651_Output_0', [#], [1 x 300]), Output('Times1660_Output_0', [#], [300]), Output('Block2931_Output_0', [#], [1 x 900]), Output('Block2899_Output_0', [#], [1 x 900]), Output('Splice2518_Output_0', [#], [1 x 900]), Output('Slice2515_Output_0', [#], [1 x 300]), Output('ReLU730_Output_0', [#], [300]), Output('Plus727_Output_0', [#], [300]), Output('Times721_Output_0', [#], [300]), Output('Squeeze718_Output_0', [#], [300]), Output('Slice715_Output_0', [#], [1 x 300]), Output('Times724_Output_0', [#], [300]), Output('ReLU1684_Output_0', [#], [300]), Output('Plus1681_Output_0', [#], [300]), Output('Times1675_Output_0', [#], [300]), Output('Squeeze1672_Output_0', [#], [300]), Output('Slice1669_Output_0', [#], [1 x 300]), Output('Times1678_Output_0', [#], [300]), Output('Splice2524_Output_0', [#], [1 x 900]), Output('Slice2521_Output_0', [#], [1 x 300]), Output('ReLU748_Output_0', [#], [300]), Output('Plus745_Output_0', [#], [300]), Output('Times739_Output_0', [#], [300]), Output('Squeeze736_Output_0', [#], [300]), Output('Slice733_Output_0', [#], [1 x 300]), Output('Times742_Output_0', [#], [300]), Output('ReLU1702_Output_0', [#], [300]), Output('Plus1699_Output_0', [#], [300]), Output('Times1693_Output_0', [#], [300]), Output('Squeeze1690_Output_0', [#], [300]), Output('Slice1687_Output_0', [#], [1 x 300]), Output('Times1696_Output_0', [#], [300]), Output('Block2915_Output_0', [#], [1 x 900]), Output('Splice2530_Output_0', [#], [1 x 900]), Output('Slice2527_Output_0', [#], [1 x 300]), Output('ReLU766_Output_0', [#], [300]), Output('Plus763_Output_0', [#], [300]), Output('Times757_Output_0', [#], [300]), Output('Squeeze754_Output_0', [#], [300]), Output('Slice751_Output_0', [#], [1 x 300]), Output('Times760_Output_0', [#], [300]), Output('ReLU1720_Output_0', [#], [300]), Output('Plus1717_Output_0', [#], [300]), Output('Times1711_Output_0', [#], [300]), Output('Squeeze1708_Output_0', [#], [300]), Output('Slice1705_Output_0', [#], [1 x 300]), Output('Times1714_Output_0', [#], [300]), Output('Splice2536_Output_0', [#], [1 x 900]), Output('Slice2533_Output_0', [#], [1 x 300]), Output('ReLU784_Output_0', [#], [300]), Output('Plus781_Output_0', [#], [300]), Output('Times775_Output_0', [#], [300]), Output('Squeeze772_Output_0', [#], [300]), Output('Slice769_Output_0', [#], [1 x 300]), Output('Times778_Output_0', [#], [300]), Output('ReLU1738_Output_0', [#], [300]), Output('Plus1735_Output_0', [#], [300]), Output('Times1729_Output_0', [#], [300]), Output('Squeeze1726_Output_0', [#], [300]), Output('Slice1723_Output_0', [#], [1 x 300]), Output('Times1732_Output_0', [#], [300]), Output('Block3155_Output_0', [#], [1 x 900]), Output('Block3043_Output_0', [#], [1 x 900]), Output('Block2995_Output_0', [#], [1 x 900]), Output('Splice2542_Output_0', [#], [1 x 900]), Output('Slice2539_Output_0', [#], [1 x 300]), Output('ReLU802_Output_0', [#], [300]), Output('Plus799_Output_0', [#], [300]), Output('Times793_Output_0', [#], [300]), Output('Squeeze790_Output_0', [#], [300]), Output('Slice787_Output_0', [#], [1 x 300]), Output('Times796_Output_0', [#], [300]), Output('ReLU1756_Output_0', [#], [300]), Output('Plus1753_Output_0', [#], [300]), Output('Times1747_Output_0', [#], [300]), Output('Squeeze1744_Output_0', [#], [300]), Output('Slice1741_Output_0', [#], [1 x 300]), Output('Times1750_Output_0', [#], [300]), Output('Block2979_Output_0', [#], [1 x 900]), Output('Splice2548_Output_0', [#], [1 x 900]), Output('Slice2545_Output_0', [#], [1 x 300]), Output('ReLU820_Output_0', [#], [300]), Output('Plus817_Output_0', [#], [300]), Output('Times811_Output_0', [#], [300]), Output('Squeeze808_Output_0', [#], [300]), Output('Slice805_Output_0', [#], [1 x 300]), Output('Times814_Output_0', [#], [300]), Output('ReLU1774_Output_0', [#], [300]), Output('Plus1771_Output_0', [#], [300]), Output('Times1765_Output_0', [#], [300]), Output('Squeeze1762_Output_0', [#], [300]), Output('Slice1759_Output_0', [#], [1 x 300]), Output('Times1768_Output_0', [#], [300]), Output('Splice2554_Output_0', [#], [1 x 900]), Output('Slice2551_Output_0', [#], [1 x 300]), Output('ReLU838_Output_0', [#], [300]), Output('Plus835_Output_0', [#], [300]), Output('Times829_Output_0', [#], [300]), Output('Squeeze826_Output_0', [#], [300]), Output('Slice823_Output_0', [#], [1 x 300]), Output('Times832_Output_0', [#], [300]), Output('ReLU1792_Output_0', [#], [300]), Output('Plus1789_Output_0', [#], [300]), Output('Times1783_Output_0', [#], [300]), Output('Squeeze1780_Output_0', [#], [300]), Output('Slice1777_Output_0', [#], [1 x 300]), Output('Times1786_Output_0', [#], [300]), Output('Block3027_Output_0', [#], [1 x 900]), Output('Splice2560_Output_0', [#], [1 x 900]), Output('Slice2557_Output_0', [#], [1 x 300]), Output('ReLU856_Output_0', [#], [300]), Output('Plus853_Output_0', [#], [300]), Output('Times847_Output_0', [#], [300]), Output('Squeeze844_Output_0', [#], [300]), Output('Slice841_Output_0', [#], [1 x 300]), Output('Times850_Output_0', [#], [300]), Output('ReLU1810_Output_0', [#], [300]), Output('Plus1807_Output_0', [#], [300]), Output('Times1801_Output_0', [#], [300]), Output('Squeeze1798_Output_0', [#], [300]), Output('Slice1795_Output_0', [#], [1 x 300]), Output('Times1804_Output_0', [#], [300]), Output('Block3011_Output_0', [#], [1 x 900]), Output('Splice2566_Output_0', [#], [1 x 900]), Output('Slice2563_Output_0', [#], [1 x 300]), Output('ReLU874_Output_0', [#], [300]), Output('Plus871_Output_0', [#], [300]), Output('Times865_Output_0', [#], [300]), Output('Squeeze862_Output_0', [#], [300]), Output('Slice859_Output_0', [#], [1 x 300]), Output('Times868_Output_0', [#], [300]), Output('ReLU1828_Output_0', [#], [300]), Output('Plus1825_Output_0', [#], [300]), Output('Times1819_Output_0', [#], [300]), Output('Squeeze1816_Output_0', [#], [300]), Output('Slice1813_Output_0', [#], [1 x 300]), Output('Times1822_Output_0', [#], [300]), Output('Splice2572_Output_0', [#], [1 x 900]), Output('Slice2569_Output_0', [#], [1 x 300]), Output('ReLU892_Output_0', [#], [300]), Output('Plus889_Output_0', [#], [300]), Output('Times883_Output_0', [#], [300]), Output('Squeeze880_Output_0', [#], [300]), Output('Slice877_Output_0', [#], [1 x 300]), Output('Times886_Output_0', [#], [300]), Output('ReLU1846_Output_0', [#], [300]), Output('Plus1843_Output_0', [#], [300]), Output('Times1837_Output_0', [#], [300]), Output('Squeeze1834_Output_0', [#], [300]), Output('Slice1831_Output_0', [#], [1 x 300]), Output('Times1840_Output_0', [#], [300]), Output('Block3139_Output_0', [#], [1 x 900]), Output('Block3075_Output_0', [#], [1 x 900]), Output('Splice2578_Output_0', [#], [1 x 900]), Output('Slice2575_Output_0', [#], [1 x 300]), Output('ReLU910_Output_0', [#], [300]), Output('Plus907_Output_0', [#], [300]), Output('Times901_Output_0', [#], [300]), Output('Squeeze898_Output_0', [#], [300]), Output('Slice895_Output_0', [#], [1 x 300]), Output('Times904_Output_0', [#], [300]), Output('ReLU1864_Output_0', [#], [300]), Output('Plus1861_Output_0', [#], [300]), Output('Times1855_Output_0', [#], [300]), Output('Squeeze1852_Output_0', [#], [300]), Output('Slice1849_Output_0', [#], [1 x 300]), Output('Times1858_Output_0', [#], [300]), Output('Block3059_Output_0', [#], [1 x 900]), Output('Splice2584_Output_0', [#], [1 x 900]), Output('Slice2581_Output_0', [#], [1 x 300]), Output('ReLU928_Output_0', [#], [300]), Output('Plus925_Output_0', [#], [300]), Output('Times919_Output_0', [#], [300]), Output('Squeeze916_Output_0', [#], [300]), Output('Slice913_Output_0', [#], [1 x 300]), Output('Times922_Output_0', [#], [300]), Output('ReLU1882_Output_0', [#], [300]), Output('Plus1879_Output_0', [#], [300]), Output('Times1873_Output_0', [#], [300]), Output('Squeeze1870_Output_0', [#], [300]), Output('Slice1867_Output_0', [#], [1 x 300]), Output('Times1876_Output_0', [#], [300]), Output('Splice2590_Output_0', [#], [1 x 900]), Output('Slice2587_Output_0', [#], [1 x 300]), Output('ReLU946_Output_0', [#], [300]), Output('Plus943_Output_0', [#], [300]), Output('Times937_Output_0', [#], [300]), Output('Squeeze934_Output_0', [#], [300]), Output('Slice931_Output_0', [#], [1 x 300]), Output('Times940_Output_0', [#], [300]), Output('ReLU1900_Output_0', [#], [300]), Output('Plus1897_Output_0', [#], [300]), Output('Times1891_Output_0', [#], [300]), Output('Squeeze1888_Output_0', [#], [300]), Output('Slice1885_Output_0', [#], [1 x 300]), Output('Times1894_Output_0', [#], [300]), Output('Block3123_Output_0', [#], [1 x 900]), Output('Block3091_Output_0', [#], [1 x 900]), Output('Splice2596_Output_0', [#], [1 x 900]), Output('Slice2593_Output_0', [#], [1 x 300]), Output('ReLU964_Output_0', [#], [300]), Output('Plus961_Output_0', [#], [300]), Output('Times955_Output_0', [#], [300]), Output('Squeeze952_Output_0', [#], [300]), Output('Slice949_Output_0', [#], [1 x 300]), Output('Times958_Output_0', [#], [300]), Output('ReLU1918_Output_0', [#], [300]), Output('Plus1915_Output_0', [#], [300]), Output('Times1909_Output_0', [#], [300]), Output('Squeeze1906_Output_0', [#], [300]), Output('Slice1903_Output_0', [#], [1 x 300]), Output('Times1912_Output_0', [#], [300]), Output('Splice2602_Output_0', [#], [1 x 900]), Output('Slice2599_Output_0', [#], [1 x 300]), Output('ReLU982_Output_0', [#], [300]), Output('Plus979_Output_0', [#], [300]), Output('Times973_Output_0', [#], [300]), Output('Squeeze970_Output_0', [#], [300]), Output('Slice967_Output_0', [#], [1 x 300]), Output('Times976_Output_0', [#], [300]), Output('ReLU1936_Output_0', [#], [300]), Output('Plus1933_Output_0', [#], [300]), Output('Times1927_Output_0', [#], [300]), Output('Squeeze1924_Output_0', [#], [300]), Output('Slice1921_Output_0', [#], [1 x 300]), Output('Times1930_Output_0', [#], [300]), Output('Block3107_Output_0', [#], [1 x 900]), Output('Splice2608_Output_0', [#], [1 x 900]), Output('Slice2605_Output_0', [#], [1 x 300]), Output('ReLU1000_Output_0', [#], [300]), Output('Plus997_Output_0', [#], [300]), Output('Times991_Output_0', [#], [300]), Output('Squeeze988_Output_0', [#], [300]), Output('Slice985_Output_0', [#], [1 x 300]), Output('Times994_Output_0', [#], [300]), Output('ReLU1954_Output_0', [#], [300]), Output('Plus1951_Output_0', [#], [300]), Output('Times1945_Output_0', [#], [300]), Output('Squeeze1942_Output_0', [#], [300]), Output('Slice1939_Output_0', [#], [1 x 300]), Output('Times1948_Output_0', [#], [300]), Output('Splice2614_Output_0', [#], [1 x 900]), Output('Slice2611_Output_0', [#], [1 x 300]), Output('ReLU1018_Output_0', [#], [300]), Output('Plus1015_Output_0', [#], [300]), Output('Times1009_Output_0', [#], [300]), Output('Squeeze1006_Output_0', [#], [300]), Output('Slice1003_Output_0', [#], [1 x 300]), Output('Times1012_Output_0', [#], [300]), Output('ReLU1972_Output_0', [#], [300]), Output('Plus1969_Output_0', [#], [300]), Output('Times1963_Output_0', [#], [300]), Output('Squeeze1960_Output_0', [#], [300]), Output('Slice1957_Output_0', [#], [1 x 300]), Output('Times1966_Output_0', [#], [300]), Output('Block3587_Output_0', [#], [1 x 900]), Output('Block3363_Output_0', [#], [1 x 900]), Output('Block3251_Output_0', [#], [1 x 900]), Output('Block3203_Output_0', [#], [1 x 900]), Output('Splice2620_Output_0', [#], [1 x 900]), Output('Slice2617_Output_0', [#], [1 x 300]), Output('ReLU1036_Output_0', [#], [300]), Output('Plus1033_Output_0', [#], [300]), Output('Times1027_Output_0', [#], [300]), Output('Squeeze1024_Output_0', [#], [300]), Output('Slice1021_Output_0', [#], [1 x 300]), Output('Times1030_Output_0', [#], [300]), Output('ReLU1990_Output_0', [#], [300]), Output('Plus1987_Output_0', [#], [300]), Output('Times1981_Output_0', [#], [300]), Output('Squeeze1978_Output_0', [#], [300]), Output('Slice1975_Output_0', [#], [1 x 300]), Output('Times1984_Output_0', [#], [300]), Output('Block3187_Output_0', [#], [1 x 900]), Output('Splice2626_Output_0', [#], [1 x 900]), Output('Slice2623_Output_0', [#], [1 x 300]), Output('ReLU1054_Output_0', [#], [300]), Output('Plus1051_Output_0', [#], [300]), Output('Times1045_Output_0', [#], [300]), Output('Squeeze1042_Output_0', [#], [300]), Output('Slice1039_Output_0', [#], [1 x 300]), Output('Times1048_Output_0', [#], [300]), Output('ReLU2008_Output_0', [#], [300]), Output('Plus2005_Output_0', [#], [300]), Output('Times1999_Output_0', [#], [300]), Output('Squeeze1996_Output_0', [#], [300]), Output('Slice1993_Output_0', [#], [1 x 300]), Output('Times2002_Output_0', [#], [300]), Output('Splice2632_Output_0', [#], [1 x 900]), Output('Slice2629_Output_0', [#], [1 x 300]), Output('ReLU1072_Output_0', [#], [300]), Output('Plus1069_Output_0', [#], [300]), Output('Times1063_Output_0', [#], [300]), Output('Squeeze1060_Output_0', [#], [300]), Output('Slice1057_Output_0', [#], [1 x 300]), Output('Times1066_Output_0', [#], [300]), Output('ReLU2026_Output_0', [#], [300]), Output('Plus2023_Output_0', [#], [300]), Output('Times2017_Output_0', [#], [300]), Output('Squeeze2014_Output_0', [#], [300]), Output('Slice2011_Output_0', [#], [1 x 300]), Output('Times2020_Output_0', [#], [300]), Output('Block3235_Output_0', [#], [1 x 900]), Output('Splice2638_Output_0', [#], [1 x 900]), Output('Slice2635_Output_0', [#], [1 x 300]), Output('ReLU1090_Output_0', [#], [300]), Output('Plus1087_Output_0', [#], [300]), Output('Times1081_Output_0', [#], [300]), Output('Squeeze1078_Output_0', [#], [300]), Output('Slice1075_Output_0', [#], [1 x 300]), Output('Times1084_Output_0', [#], [300]), Output('ReLU2044_Output_0', [#], [300]), Output('Plus2041_Output_0', [#], [300]), Output('Times2035_Output_0', [#], [300]), Output('Squeeze2032_Output_0', [#], [300]), Output('Slice2029_Output_0', [#], [1 x 300]), Output('Times2038_Output_0', [#], [300]), Output('Block3219_Output_0', [#], [1 x 900]), Output('Splice2644_Output_0', [#], [1 x 900]), Output('Slice2641_Output_0', [#], [1 x 300]), Output('ReLU1108_Output_0', [#], [300]), Output('Plus1105_Output_0', [#], [300]), Output('Times1099_Output_0', [#], [300]), Output('Squeeze1096_Output_0', [#], [300]), Output('Slice1093_Output_0', [#], [1 x 300]), Output('Times1102_Output_0', [#], [300]), Output('ReLU2062_Output_0', [#], [300]), Output('Plus2059_Output_0', [#], [300]), Output('Times2053_Output_0', [#], [300]), Output('Squeeze2050_Output_0', [#], [300]), Output('Slice2047_Output_0', [#], [1 x 300]), Output('Times2056_Output_0', [#], [300]), Output('Splice2650_Output_0', [#], [1 x 900]), Output('Slice2647_Output_0', [#], [1 x 300]), Output('ReLU1126_Output_0', [#], [300]), Output('Plus1123_Output_0', [#], [300]), Output('Times1117_Output_0', [#], [300]), Output('Squeeze1114_Output_0', [#], [300]), Output('Slice1111_Output_0', [#], [1 x 300]), Output('Times1120_Output_0', [#], [300]), Output('ReLU2080_Output_0', [#], [300]), Output('Plus2077_Output_0', [#], [300]), Output('Times2071_Output_0', [#], [300]), Output('Squeeze2068_Output_0', [#], [300]), Output('Slice2065_Output_0', [#], [1 x 300]), Output('Times2074_Output_0', [#], [300]), Output('Block3347_Output_0', [#], [1 x 900]), Output('Block3283_Output_0', [#], [1 x 900]), Output('Splice2656_Output_0', [#], [1 x 900]), Output('Slice2653_Output_0', [#], [1 x 300]), Output('ReLU1144_Output_0', [#], [300]), Output('Plus1141_Output_0', [#], [300]), Output('Times1135_Output_0', [#], [300]), Output('Squeeze1132_Output_0', [#], [300]), Output('Slice1129_Output_0', [#], [1 x 300]), Output('Times1138_Output_0', [#], [300]), Output('ReLU2098_Output_0', [#], [300]), Output('Plus2095_Output_0', [#], [300]), Output('Times2089_Output_0', [#], [300]), Output('Squeeze2086_Output_0', [#], [300]), Output('Slice2083_Output_0', [#], [1 x 300]), Output('Times2092_Output_0', [#], [300]), Output('Block3267_Output_0', [#], [1 x 900]), Output('Splice2662_Output_0', [#], [1 x 900]), Output('Slice2659_Output_0', [#], [1 x 300]), Output('ReLU1162_Output_0', [#], [300]), Output('Plus1159_Output_0', [#], [300]), Output('Times1153_Output_0', [#], [300]), Output('Squeeze1150_Output_0', [#], [300]), Output('Slice1147_Output_0', [#], [1 x 300]), Output('Times1156_Output_0', [#], [300]), Output('ReLU2116_Output_0', [#], [300]), Output('Plus2113_Output_0', [#], [300]), Output('Times2107_Output_0', [#], [300]), Output('Squeeze2104_Output_0', [#], [300]), Output('Slice2101_Output_0', [#], [1 x 300]), Output('Times2110_Output_0', [#], [300]), Output('Splice2668_Output_0', [#], [1 x 900]), Output('Slice2665_Output_0', [#], [1 x 300]), Output('ReLU1180_Output_0', [#], [300]), Output('Plus1177_Output_0', [#], [300]), Output('Times1171_Output_0', [#], [300]), Output('Squeeze1168_Output_0', [#], [300]), Output('Slice1165_Output_0', [#], [1 x 300]), Output('Times1174_Output_0', [#], [300]), Output('ReLU2134_Output_0', [#], [300]), Output('Plus2131_Output_0', [#], [300]), Output('Times2125_Output_0', [#], [300]), Output('Squeeze2122_Output_0', [#], [300]), Output('Slice2119_Output_0', [#], [1 x 300]), Output('Times2128_Output_0', [#], [300]), Output('Block3331_Output_0', [#], [1 x 900]), Output('Block3299_Output_0', [#], [1 x 900]), Output('Splice2674_Output_0', [#], [1 x 900]), Output('Slice2671_Output_0', [#], [1 x 300]), Output('ReLU1198_Output_0', [#], [300]), Output('Plus1195_Output_0', [#], [300]), Output('Times1189_Output_0', [#], [300]), Output('Squeeze1186_Output_0', [#], [300]), Output('Slice1183_Output_0', [#], [1 x 300]), Output('Times1192_Output_0', [#], [300]), Output('ReLU2152_Output_0', [#], [300]), Output('Plus2149_Output_0', [#], [300]), Output('Times2143_Output_0', [#], [300]), Output('Squeeze2140_Output_0', [#], [300]), Output('Slice2137_Output_0', [#], [1 x 300]), Output('Times2146_Output_0', [#], [300]), Output('Splice2680_Output_0', [#], [1 x 900]), Output('Slice2677_Output_0', [#], [1 x 300]), Output('ReLU1216_Output_0', [#], [300]), Output('Plus1213_Output_0', [#], [300]), Output('Times1207_Output_0', [#], [300]), Output('Squeeze1204_Output_0', [#], [300]), Output('Slice1201_Output_0', [#], [1 x 300]), Output('Times1210_Output_0', [#], [300]), Output('ReLU2170_Output_0', [#], [300]), Output('Plus2167_Output_0', [#], [300]), Output('Times2161_Output_0', [#], [300]), Output('Squeeze2158_Output_0', [#], [300]), Output('Slice2155_Output_0', [#], [1 x 300]), Output('Times2164_Output_0', [#], [300]), Output('Block3315_Output_0', [#], [1 x 900]), Output('Splice2686_Output_0', [#], [1 x 900]), Output('Slice2683_Output_0', [#], [1 x 300]), Output('ReLU1234_Output_0', [#], [300]), Output('Plus1231_Output_0', [#], [300]), Output('Times1225_Output_0', [#], [300]), Output('Squeeze1222_Output_0', [#], [300]), Output('Slice1219_Output_0', [#], [1 x 300]), Output('Times1228_Output_0', [#], [300]), Output('ReLU2188_Output_0', [#], [300]), Output('Plus2185_Output_0', [#], [300]), Output('Times2179_Output_0', [#], [300]), Output('Squeeze2176_Output_0', [#], [300]), Output('Slice2173_Output_0', [#], [1 x 300]), Output('Times2182_Output_0', [#], [300]), Output('Splice2692_Output_0', [#], [1 x 900]), Output('Slice2689_Output_0', [#], [1 x 300]), Output('ReLU1252_Output_0', [#], [300]), Output('Plus1249_Output_0', [#], [300]), Output('Times1243_Output_0', [#], [300]), Output('Squeeze1240_Output_0', [#], [300]), Output('Slice1237_Output_0', [#], [1 x 300]), Output('Times1246_Output_0', [#], [300]), Output('ReLU2206_Output_0', [#], [300]), Output('Plus2203_Output_0', [#], [300]), Output('Times2197_Output_0', [#], [300]), Output('Squeeze2194_Output_0', [#], [300]), Output('Slice2191_Output_0', [#], [1 x 300]), Output('Times2200_Output_0', [#], [300]), Output('Block3571_Output_0', [#], [1 x 900]), Output('Block3459_Output_0', [#], [1 x 900]), Output('Block3395_Output_0', [#], [1 x 900]), Output('Splice2698_Output_0', [#], [1 x 900]), Output('Slice2695_Output_0', [#], [1 x 300]), Output('ReLU1270_Output_0', [#], [300]), Output('Plus1267_Output_0', [#], [300]), Output('Times1261_Output_0', [#], [300]), Output('Squeeze1258_Output_0', [#], [300]), Output('Slice1255_Output_0', [#], [1 x 300]), Output('Times1264_Output_0', [#], [300]), Output('ReLU2224_Output_0', [#], [300]), Output('Plus2221_Output_0', [#], [300]), Output('Times2215_Output_0', [#], [300]), Output('Squeeze2212_Output_0', [#], [300]), Output('Slice2209_Output_0', [#], [1 x 300]), Output('Times2218_Output_0', [#], [300]), Output('Block3379_Output_0', [#], [1 x 900]), Output('Splice2704_Output_0', [#], [1 x 900]), Output('Slice2701_Output_0', [#], [1 x 300]), Output('ReLU1288_Output_0', [#], [300]), Output('Plus1285_Output_0', [#], [300]), Output('Times1279_Output_0', [#], [300]), Output('Squeeze1276_Output_0', [#], [300]), Output('Slice1273_Output_0', [#], [1 x 300]), Output('Times1282_Output_0', [#], [300]), Output('ReLU2242_Output_0', [#], [300]), Output('Plus2239_Output_0', [#], [300]), Output('Times2233_Output_0', [#], [300]), Output('Squeeze2230_Output_0', [#], [300]), Output('Slice2227_Output_0', [#], [1 x 300]), Output('Times2236_Output_0', [#], [300]), Output('Splice2710_Output_0', [#], [1 x 900]), Output('Slice2707_Output_0', [#], [1 x 300]), Output('ReLU1306_Output_0', [#], [300]), Output('Plus1303_Output_0', [#], [300]), Output('Times1297_Output_0', [#], [300]), Output('Squeeze1294_Output_0', [#], [300]), Output('Slice1291_Output_0', [#], [1 x 300]), Output('Times1300_Output_0', [#], [300]), Output('ReLU2260_Output_0', [#], [300]), Output('Plus2257_Output_0', [#], [300]), Output('Times2251_Output_0', [#], [300]), Output('Squeeze2248_Output_0', [#], [300]), Output('Slice2245_Output_0', [#], [1 x 300]), Output('Times2254_Output_0', [#], [300]), Output('Block3443_Output_0', [#], [1 x 900]), Output('Block3411_Output_0', [#], [1 x 900]), Output('Splice2716_Output_0', [#], [1 x 900]), Output('Slice2713_Output_0', [#], [1 x 300]), Output('ReLU1324_Output_0', [#], [300]), Output('Plus1321_Output_0', [#], [300]), Output('Times1315_Output_0', [#], [300]), Output('Squeeze1312_Output_0', [#], [300]), Output('Slice1309_Output_0', [#], [1 x 300]), Output('Times1318_Output_0', [#], [300]), Output('ReLU2278_Output_0', [#], [300]), Output('Plus2275_Output_0', [#], [300]), Output('Times2269_Output_0', [#], [300]), Output('Squeeze2266_Output_0', [#], [300]), Output('Slice2263_Output_0', [#], [1 x 300]), Output('Times2272_Output_0', [#], [300]), Output('Splice2722_Output_0', [#], [1 x 900]), Output('Slice2719_Output_0', [#], [1 x 300]), Output('ReLU1342_Output_0', [#], [300]), Output('Plus1339_Output_0', [#], [300]), Output('Times1333_Output_0', [#], [300]), Output('Squeeze1330_Output_0', [#], [300]), Output('Slice1327_Output_0', [#], [1 x 300]), Output('Times1336_Output_0', [#], [300]), Output('ReLU2296_Output_0', [#], [300]), Output('Plus2293_Output_0', [#], [300]), Output('Times2287_Output_0', [#], [300]), Output('Squeeze2284_Output_0', [#], [300]), Output('Slice2281_Output_0', [#], [1 x 300]), Output('Times2290_Output_0', [#], [300]), Output('Block3427_Output_0', [#], [1 x 900]), Output('Splice2728_Output_0', [#], [1 x 900]), Output('Slice2725_Output_0', [#], [1 x 300]), Output('ReLU1360_Output_0', [#], [300]), Output('Plus1357_Output_0', [#], [300]), Output('Times1351_Output_0', [#], [300]), Output('Squeeze1348_Output_0', [#], [300]), Output('Slice1345_Output_0', [#], [1 x 300]), Output('Times1354_Output_0', [#], [300]), Output('ReLU2314_Output_0', [#], [300]), Output('Plus2311_Output_0', [#], [300]), Output('Times2305_Output_0', [#], [300]), Output('Squeeze2302_Output_0', [#], [300]), Output('Slice2299_Output_0', [#], [1 x 300]), Output('Times2308_Output_0', [#], [300]), Output('Splice2734_Output_0', [#], [1 x 900]), Output('Slice2731_Output_0', [#], [1 x 300]), Output('ReLU1378_Output_0', [#], [300]), Output('Plus1375_Output_0', [#], [300]), Output('Times1369_Output_0', [#], [300]), Output('Squeeze1366_Output_0', [#], [300]), Output('Slice1363_Output_0', [#], [1 x 300]), Output('Times1372_Output_0', [#], [300]), Output('ReLU2332_Output_0', [#], [300]), Output('Plus2329_Output_0', [#], [300]), Output('Times2323_Output_0', [#], [300]), Output('Squeeze2320_Output_0', [#], [300]), Output('Slice2317_Output_0', [#], [1 x 300]), Output('Times2326_Output_0', [#], [300]), Output('Block3555_Output_0', [#], [1 x 900]), Output('Block3491_Output_0', [#], [1 x 900]), Output('Splice2740_Output_0', [#], [1 x 900]), Output('Slice2737_Output_0', [#], [1 x 300]), Output('ReLU1396_Output_0', [#], [300]), Output('Plus1393_Output_0', [#], [300]), Output('Times1387_Output_0', [#], [300]), Output('Squeeze1384_Output_0', [#], [300]), Output('Slice1381_Output_0', [#], [1 x 300]), Output('Times1390_Output_0', [#], [300]), Output('ReLU2350_Output_0', [#], [300]), Output('Plus2347_Output_0', [#], [300]), Output('Times2341_Output_0', [#], [300]), Output('Squeeze2338_Output_0', [#], [300]), Output('Slice2335_Output_0', [#], [1 x 300]), Output('Times2344_Output_0', [#], [300]), Output('Block3475_Output_0', [#], [1 x 900]), Output('Splice2746_Output_0', [#], [1 x 900]), Output('Slice2743_Output_0', [#], [1 x 300]), Output('ReLU1414_Output_0', [#], [300]), Output('Plus1411_Output_0', [#], [300]), Output('Times1405_Output_0', [#], [300]), Output('Squeeze1402_Output_0', [#], [300]), Output('Slice1399_Output_0', [#], [1 x 300]), Output('Times1408_Output_0', [#], [300]), Output('ReLU2368_Output_0', [#], [300]), Output('Plus2365_Output_0', [#], [300]), Output('Times2359_Output_0', [#], [300]), Output('Squeeze2356_Output_0', [#], [300]), Output('Slice2353_Output_0', [#], [1 x 300]), Output('Times2362_Output_0', [#], [300]), Output('Splice2752_Output_0', [#], [1 x 900]), Output('Slice2749_Output_0', [#], [1 x 300]), Output('ReLU1432_Output_0', [#], [300]), Output('Plus1429_Output_0', [#], [300]), Output('Times1423_Output_0', [#], [300]), Output('Squeeze1420_Output_0', [#], [300]), Output('Slice1417_Output_0', [#], [1 x 300]), Output('Times1426_Output_0', [#], [300]), Output('ReLU2386_Output_0', [#], [300]), Output('Plus2383_Output_0', [#], [300]), Output('Times2377_Output_0', [#], [300]), Output('Squeeze2374_Output_0', [#], [300]), Output('Slice2371_Output_0', [#], [1 x 300]), Output('Times2380_Output_0', [#], [300]), Output('Block3539_Output_0', [#], [1 x 900]), Output('Block3507_Output_0', [#], [1 x 900]), Output('Splice2758_Output_0', [#], [1 x 900]), Output('Slice2755_Output_0', [#], [1 x 300]), Output('ReLU1450_Output_0', [#], [300]), Output('Plus1447_Output_0', [#], [300]), Output('Times1441_Output_0', [#], [300]), Output('Squeeze1438_Output_0', [#], [300]), Output('Slice1435_Output_0', [#], [1 x 300]), Output('Times1444_Output_0', [#], [300]), Output('ReLU2404_Output_0', [#], [300]), Output('Plus2401_Output_0', [#], [300]), Output('Times2395_Output_0', [#], [300]), Output('Squeeze2392_Output_0', [#], [300]), Output('Slice2389_Output_0', [#], [1 x 300]), Output('Times2398_Output_0', [#], [300]), Output('Splice2764_Output_0', [#], [1 x 900]), Output('Slice2761_Output_0', [#], [1 x 300]), Output('ReLU1468_Output_0', [#], [300]), Output('Plus1465_Output_0', [#], [300]), Output('Times1459_Output_0', [#], [300]), Output('Squeeze1456_Output_0', [#], [300]), Output('Slice1453_Output_0', [#], [1 x 300]), Output('Times1462_Output_0', [#], [300]), Output('ReLU2422_Output_0', [#], [300]), Output('Plus2419_Output_0', [#], [300]), Output('Times2413_Output_0', [#], [300]), Output('Squeeze2410_Output_0', [#], [300]), Output('Slice2407_Output_0', [#], [1 x 300]), Output('Times2416_Output_0', [#], [300]), Output('Block3523_Output_0', [#], [1 x 900]), Output('Splice2770_Output_0', [#], [1 x 900]), Output('Slice2767_Output_0', [#], [1 x 300]), Output('ReLU1486_Output_0', [#], [300]), Output('Plus1483_Output_0', [#], [300]), Output('Times1477_Output_0', [#], [300]), Output('Squeeze1474_Output_0', [#], [300]), Output('Slice1471_Output_0', [#], [1 x 300]), Output('Times1480_Output_0', [#], [300]), Output('ReLU2440_Output_0', [#], [300]), Output('Plus2437_Output_0', [#], [300]), Output('Times2431_Output_0', [#], [300]), Output('Squeeze2428_Output_0', [#], [300]), Output('Slice2425_Output_0', [#], [1 x 300]), Output('Times2434_Output_0', [#], [300]), Output('Splice2776_Output_0', [#], [1 x 900]), Output('Slice2773_Output_0', [#], [1 x 300]), Output('ReLU1504_Output_0', [#], [300]), Output('Plus1501_Output_0', [#], [300]), Output('Times1495_Output_0', [#], [300]), Output('Squeeze1492_Output_0', [#], [300]), Output('Slice1489_Output_0', [#], [1 x 300]), Output('Times1498_Output_0', [#], [300]), Output('ReLU2458_Output_0', [#], [300]), Output('Plus2455_Output_0', [#], [300]), Output('Times2449_Output_0', [#], [300]), Output('Squeeze2446_Output_0', [#], [300]), Output('Slice2443_Output_0', [#], [1 x 300]), Output('Times2452_Output_0', [#], [300])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size:  768505 batch_size:  150 num_batches_per_epoch:  5124\n",
      "Learning rate per minibatch: 0.007500000000000001\n",
      "1000 452.5599956512451\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t-haohu/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/ipykernel_launcher.py:222: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.07805828257326863 Recall:0.5772122301060411 Acc:0.2775352198202575\n",
      "2000 519.9972846508026\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.26899635190623306 Recall:0.4629667026318552 Acc:0.5501335924216663\n",
      "3000 531.0107970237732\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.4226878264063057 Recall:0.6556260489071323 Acc:0.6633470974010202\n",
      "4000 522.5568284988403\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.5245511046497094 Recall:0.7292083594442433 Acc:0.7269279815399563\n",
      "5000 539.5361003875732\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.5860393298938087 Recall:0.7537261655713151 Acc:0.7634260383774593\n",
      "6000 530.0673816204071\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.6211940668753323 Recall:0.773050810345837 Acc:0.7824690308477047\n",
      "7000 478.32836627960205\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.6538681415896267 Recall:0.7823695758962121 Acc:0.7978351955307262\n",
      "8000 410.6563866138458\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.6711789878223764 Recall:0.7986870481304313 Acc:0.8072595336410008\n",
      "9000 432.0167467594147\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.6850457611924887 Recall:0.8006677593753824 Acc:0.8150412922030604\n",
      "10000 461.04106736183167\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7041122502015309 Recall:0.8046132410355309 Acc:0.8230902356084527\n",
      "11000 442.3446180820465\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7176926865308606 Recall:0.8058138334902458 Acc:0.827808477046393\n",
      "12000 483.38279008865356\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7258179259105736 Recall:0.8107512242296742 Acc:0.8314944134078213\n",
      "13000 533.5822961330414\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7331592528487868 Recall:0.8239640409659911 Acc:0.8350923002186058\n",
      "14000 547.1133005619049\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7389259945243712 Recall:0.826749710121003 Acc:0.8385019431624969\n",
      "15000 568.8380303382874\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7467753406059728 Recall:0.8269361144368383 Acc:0.8414045421423366\n",
      "16000 551.0429215431213\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7510611854650066 Recall:0.8166689367985457 Acc:0.8428224435268399\n",
      "17000 556.898190498352\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7544467087681476 Recall:0.8190705194715591 Acc:0.8440217391304348\n",
      "18000 573.0170662403107\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7561944815723055 Recall:0.8215155454199911 Acc:0.8452240709254312\n",
      "19000 549.7968482971191\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7613700157635015 Recall:0.8188290243213214 Acc:0.8470002428953122\n",
      "20000 567.5956609249115\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7652550585413451 Recall:0.8186021758897706 Acc:0.8486397862521253\n",
      "21000 567.1756973266602\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7671251998077838 Recall:0.8198988475951525 Acc:0.8493259655088656\n",
      "22000 481.425820350647\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7705784582310704 Recall:0.8169689811417832 Acc:0.849747996113675\n",
      "23000 568.2015202045441\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7733775972597373 Recall:0.8163144180767506 Acc:0.850804590721399\n",
      "24000 550.0332641601562\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7762775986516295 Recall:0.816588342806876 Acc:0.8520008501335924\n",
      "25000 559.7730431556702\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7773378319208066 Recall:0.8185473132711373 Acc:0.8528418751518095\n",
      "26000 581.1946651935577\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.77869485474881 Recall:0.8175681986991981 Acc:0.8527234636871508\n",
      "27000 585.9677991867065\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7796137706873498 Recall:0.8177609509904498 Acc:0.8527507894097643\n",
      "28000 582.7305388450623\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7808897440003918 Recall:0.818263686542192 Acc:0.8535918144279815\n",
      "29000 569.3673892021179\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7820236172675614 Recall:0.8186017049588484 Acc:0.8540533155210105\n",
      "30000 589.0533218383789\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7843360201734547 Recall:0.816520240762889 Acc:0.8544328394461986\n",
      "31000 577.8827259540558\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7855750148383224 Recall:0.8166050651159583 Acc:0.854572504250668\n",
      "32000 603.2255156040192\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7834616767661055 Recall:0.8174312674592698 Acc:0.8535644887053679\n",
      "33000 577.2848498821259\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7836866091710659 Recall:0.8183857041728736 Acc:0.8531363857177556\n",
      "34000 597.7720143795013\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7863052587712387 Recall:0.8166491049442355 Acc:0.8536920087442312\n",
      "35000 577.6565191745758\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7871963371722762 Recall:0.81697168806332 Acc:0.8541261841146466\n",
      "36000 602.396234035492\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7871362559410745 Recall:0.8171615185211623 Acc:0.85459679378188\n",
      "37000 493.77299976348877\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7881069886618607 Recall:0.8151034724944912 Acc:0.853822564974496\n",
      "38000 597.7076914310455\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7865294022790548 Recall:0.8166238379444037 Acc:0.8534400048579063\n",
      "39000 577.1949591636658\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7874218246168528 Recall:0.8157714008318507 Acc:0.8536920087442312\n",
      "40000 592.6363208293915\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7890931558113358 Recall:0.8157434814210224 Acc:0.853822564974496\n",
      "41000 578.8934535980225\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7910814670545365 Recall:0.8143936449777044 Acc:0.8542020888996842\n",
      "42000 586.2260918617249\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7878743226871141 Recall:0.8137830236499837 Acc:0.8525534369686665\n",
      "43000 590.0081443786621\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7881460077986926 Recall:0.8141444271872998 Acc:0.8525655817342725\n",
      "44000 604.6718032360077\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.790277535664624 Recall:0.8141709184974453 Acc:0.8533701724556716\n",
      "45000 582.7062475681305\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7900447859020967 Recall:0.8142319586243356 Acc:0.853576633470974\n",
      "46000 596.1837232112885\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7890322547976085 Recall:0.8143298406698615 Acc:0.8524593150352198\n",
      "47000 588.9452216625214\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7895697691983594 Recall:0.812919221733264 Acc:0.8523894826329852\n",
      "48000 481.22298192977905\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.788491741058955 Recall:0.8121794248838372 Acc:0.8514118290017003\n",
      "49000 480.22206687927246\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7878272517792493 Recall:0.8118324914893382 Acc:0.8509837260140879\n",
      "50000 460.6346514225006\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7885864243822885 Recall:0.8119079837188955 Acc:0.8509351469516638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000 475.9852411746979\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7889194146373452 Recall:0.8133846690974091 Acc:0.8520888996842361\n",
      "52000 472.6843988895416\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7895102375514061 Recall:0.8104521083541991 Acc:0.8506983240223464\n",
      "53000 490.08993554115295\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7875481004890384 Recall:0.8103429889517344 Acc:0.8503643429681808\n",
      "54000 468.53335094451904\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.786972961151962 Recall:0.8119738056231028 Acc:0.8504645372844304\n",
      "55000 476.41322565078735\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7881426421901959 Recall:0.8098805814678552 Acc:0.8501123390818557\n",
      "56000 482.90943717956543\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7869614452635222 Recall:0.8106867658758194 Acc:0.850258076269128\n",
      "57000 466.2489490509033\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7873516346196048 Recall:0.8099625923930968 Acc:0.8494291960165169\n",
      "58000 482.1373243331909\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7878125393017508 Recall:0.8068481614430849 Acc:0.848229900412922\n",
      "59000 460.1322009563446\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7877570868292054 Recall:0.807682041858734 Acc:0.8486276414865193\n",
      "60000 483.95307064056396\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.786534855768035 Recall:0.8081439425206172 Acc:0.8481145251396648\n",
      "61000 467.595773935318\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.7872318855092931 Recall:0.8078265427696939 Acc:0.8481722127762934\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/logging/progress_print.py\u001b[0m in \u001b[0;36mon_training_update_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m___write_progress_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_update_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;31m# Override for ProgressWriter.on_training_update_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m___generate_progress_heartbeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "SWIG director method error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4a800a66dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RCNN with CNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-37b6ef90bfed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, num_epochs, learning_rate, batch_size, tag, l2_weight)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mbatch_data_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m#print(type(batch_data_title),type(batch_data_title[0]),batch_data_title[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_xt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/train/trainer.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, arguments, outputs, device, is_sweep_end)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 updated = super(Trainer, self).train_minibatch(arguments, is_sweep_end,\n\u001b[0;32m--> 184\u001b[0;31m                     device)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/cntk_py.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3027\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer_train_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: SWIG director method error."
     ]
    }
   ],
   "source": [
    "train(train_data,num_epochs=20,learning_rate=[5e-5*150]*2+[1e-4*150],batch_size = 150,tag = \"RCNN with CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
