{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeded:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import time \n",
    "\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "from cntk.layers import *\n",
    "from cntk.layers.typing import *\n",
    "import pickle\n",
    "import random\n",
    "from cntk import sequence\n",
    "from cntk import load_model\n",
    "from cntk.device import try_set_default_device, gpu,cpu\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "try_set_default_device(gpu(0))\n",
    "\n",
    "\n",
    "vocab_size = 80000\n",
    "num_labels = 19#19\n",
    "title_size = 52000\n",
    "body_size  = 210000\n",
    "input_dim  = vocab_size\n",
    "label_dim  = num_labels\n",
    "emb_dim    = 300\n",
    "hidden_dim = 200\n",
    "\n",
    "max_length_title = 53\n",
    "max_length_body  = 200\n",
    "\n",
    "suffix = \"180days_all_shuffled\"\n",
    "#suffix = \"linkedin_only\"\n",
    "prefix = \"/home/t-haohu/IndustryClassifier/Data/\"\n",
    "\n",
    "#data_token_body        = \"{}/middle/{}_token_body.txt\".format(prefix,suffix)\n",
    "data_train_sample = \"{}/middle/train_{}.txt\".format(prefix,suffix)\n",
    "#data_train_sample = \"{}/middle/train_{}_with_linkedin_all.txt\".format(prefix,suffix)\n",
    "data_test_sample  = \"{}/middle/test_{}.txt\".format(prefix,suffix)\n",
    "#data_test_sample_editor  = \"{}/middle/test_{}_editor.txt\".format(prefix,suffix)\n",
    "\n",
    "data_title_sample    = \"{}/ready/title_{}.wl\".format(prefix,suffix)\n",
    "data_body_sample     = \"{}/ready/body_{}.wl\".format(prefix,suffix)\n",
    "suffix = \"180days_all_shuffled\"\n",
    "data_industry_sample = \"{}/ready/industry_{}.wl\".format(prefix,suffix)\n",
    "filter_num=200 \n",
    "dropout_rate = 0.5\n",
    "emb_dim =300\n",
    "\n",
    "def load_data(input_file,title_dict,industry_dict):\n",
    "    data = open(input_file, encoding = \"utf-8\").readlines()\n",
    "    \n",
    "    data_title =np.zeros((len(data),max_length_title),dtype = np.float32)\n",
    "    data_label = np.zeros((len(data),1),dtype = np.float32)\n",
    "       \n",
    "    for index,line in enumerate(data):\n",
    "        row = line.strip(\"\\n\").split(\"\\t\")       \n",
    "        title    =  row[0]\n",
    "        industry =  row[1]\n",
    "        \n",
    "        for jndex,token in enumerate(title.split(\" \")):\n",
    "            if jndex>=max_length_title:\n",
    "                break\n",
    "            data_title[index,jndex]=title_dict.get(token,len(title_dict)-1)    \n",
    "        data_label[index] = industry_dict.get(industry,len(industry_dict))\n",
    "    return data_title,data_label\n",
    "\n",
    "\n",
    "def load_embedding(title_file,embedding_model_file):\n",
    "    model = Word2Vec.load(embedding_model_file)\n",
    "    title_list = [x.strip(\"\\n\") for x in open(title_file,encoding = 'utf-8').readlines()]\n",
    "    embedding = np.zeros((len(title_list),emb_dim))\n",
    "    count = 0\n",
    "    for i,w in enumerate(title_list):\n",
    "        try:\n",
    "            vec = model.wv[w]\n",
    "        except:\n",
    "            vec=model.wv[\"UNK\"]\n",
    "            count+=1\n",
    "        embedding[i] =vec\n",
    "    print(\"UnEmbeded:{}\".format(count))\n",
    "    return embedding\n",
    "\n",
    "def get_context_left(current,previous,w_l,w_ls):\n",
    "    left_c = current@w_l\n",
    "    left_e = previous@w_ls\n",
    "    left_h=left_c+left_e\n",
    "    return C.relu(left_h)\n",
    "def get_context_right(current,after,w_r,w_rs):\n",
    "    right_c = current@w_r\n",
    "    right_e = after@w_rs\n",
    "    right_h =right_c+right_e\n",
    "    return C.relu(right_h)\n",
    "\n",
    "def create_model_rcnn(embed = False):\n",
    "    first_word = C.parameter(shape=(emb_dim))\n",
    "    last_word = C.parameter(shape=(emb_dim))\n",
    "    w_l,w_ls,w_r,w_rs = C.parameter(shape=(emb_dim,emb_dim)),C.parameter(shape=(emb_dim,emb_dim)),C.parameter(shape=(emb_dim,emb_dim)),C.parameter(shape=(emb_dim,emb_dim))\n",
    "    #version 2 : 1 dense layer version3: sigmoid activation in dense\n",
    "    if embed:\n",
    "        h1= C.layers.Embedding(weights=embedding,name='embed_1')(input_xt_one_hot)#\n",
    "    else:\n",
    "        h1= C.layers.Embedding(emb_dim,name='embed_2')(input_xt_one_hot)#init=embedding,\n",
    "    previous = first_word\n",
    "    # h1 [batch*sentence_length*emb_dim]\n",
    "    context_left_list = []\n",
    "    for i in range(max_length_title):\n",
    "        current = C.squeeze(h1[i])\n",
    "        context_left_list.append(get_context_left(current,previous,w_l,w_ls))\n",
    "        previous = current\n",
    "        \n",
    "    context_right_list = []\n",
    "    after = last_word\n",
    "    for i in reversed(range(max_length_title)):\n",
    "        current = C.squeeze(h1[i])\n",
    "        context_right_list.append(get_context_right(current,after,w_r,w_rs))\n",
    "        after = current\n",
    "    total_list = []\n",
    "    for i in range(max_length_title):\n",
    "        total_list.append(C.splice(h1[i],context_left_list[i],context_right_list[i]))\n",
    "    #output = C.splice(total_list)\n",
    "    #print(output)\n",
    "    #h2=BiRecurrence(C.layers.LSTM(hidden_dim), C.layers.LSTM(hidden_dim))(h1)\n",
    "    h3=C.element_max(*total_list)\n",
    "    print(h3)\n",
    "    drop1 = C.layers.Dropout(dropout_rate)(h3)\n",
    "    h4=C.layers.Dense(num_labels,name='hidden')(drop1)\n",
    "\n",
    "    return h4\n",
    "\n",
    "\n",
    "def batch_iter(data,batch_size, num_epochs, shuffle=True):\n",
    "    # Generates a batch iterator for a dataset.\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((data_size-1)/batch_size) + 1\n",
    "    print('data_size: ', data_size, 'batch_size: ', batch_size, 'num_batches_per_epoch: ', num_batches_per_epoch)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            random.shuffle(data)\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield data[start_index:end_index]\n",
    "            \n",
    "\n",
    "def fast_hist(a, b, n):\n",
    "    k = (a >= 0) & (a < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n**2).reshape(n, n)\n",
    "\n",
    "title_dict =     { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_title_sample).readlines()])}\n",
    "industry_dict =  { x:i for i,x in enumerate([x.strip(\"\\n\") for x in open(data_industry_sample).readlines()])}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_xt = C.input_variable(shape=(max_length_title),  dtype=np.float32)\n",
    "#input_xt = C.input_variable(**Sequence[Tensor[1]])\n",
    "input_y  = C.input_variable(shape=(1)               ,  dtype=np.int)\n",
    "\n",
    "input_xt_one_hot = C.one_hot(input_xt, num_classes=len(title_dict)   ,  sparse_output=True)\n",
    "input_y_one_hot = C.one_hot(input_y  , num_classes=len(industry_dict) ,  sparse_output=True)\n",
    "\n",
    "\n",
    "test_data  = load_data(data_test_sample,title_dict,industry_dict)\n",
    "train_data = load_data(data_train_sample,title_dict,industry_dict)\n",
    "#test_data_editor  = load_data(data_test_sample_editor,title_dict,industry_dict)\n",
    "embedding = load_embedding(data_title_sample,\"word2vec.model\")\n",
    "\n",
    "def test(batch_size,model,data):\n",
    "    scores = model(input_xt)\n",
    "    predict = C.argmax(scores,axis = 0)\n",
    "    confuse = np.zeros((num_labels,num_labels))\n",
    "\n",
    "    test_data_title,test_data_label = data\n",
    "    batches = batch_iter(list(zip(test_data_title,test_data_label)), batch_size, 1)\n",
    "    \n",
    "    for batch in batches:\n",
    "        batch_data_title,batch_data_label = zip(*batch) \n",
    "        output = np.array(predict.eval({input_xt: np.array(batch_data_title)}),dtype=np.int)\n",
    "        gt = np.array(batch_data_label,dtype=np.int)\n",
    "        confuse+=fast_hist(output,gt,num_labels)\n",
    "        \n",
    "    precision=np.diag(confuse)/np.sum(confuse,axis=0)\n",
    "    recall = np.diag(confuse)/np.sum(confuse,axis=1)\n",
    "    accuarcy = np.diag(confuse).sum() / confuse.sum()\n",
    "    aver_precision=np.nanmean(precision)\n",
    "    aver_recall = np.nanmean(recall)\n",
    "   \n",
    "    print(\"Precision:{} Recall:{} Acc:{}\".format(aver_precision,aver_recall,accuarcy))\n",
    "    return accuarcy\n",
    "def train(train_data,num_epochs,learning_rate,batch_size,tag=\"CNN\",l2_weight=0):\n",
    "    global model\n",
    "    #learning_rate *= batch_size\n",
    "    model = create_model_rcnn(embed = True)\n",
    "    print(C.logging.get_node_outputs(model))\n",
    "    scores = model(input_xt)\n",
    "\n",
    "    loss =C.reduce_mean(C.losses.cross_entropy_with_softmax(scores, input_y_one_hot))\n",
    "    \n",
    "    # Training\n",
    "    lr_schedule = C.learning_parameter_schedule(learning_rate)\n",
    "    #learner = C.adam(scores.parameters, lr=lr_schedule, momentum=0.9,l2_regularization_weight=0)\n",
    "    progress_printer = C.logging.ProgressPrinter(tag='Training', num_epochs=num_epochs)\n",
    "    momentums = C.momentum_schedule(0.99, minibatch_size=batch_size)\n",
    "    learner = C.adam(parameters=scores.parameters,#model.parameters,\n",
    "                     lr=lr_schedule,\n",
    "                     momentum=momentums,\n",
    "                     gradient_clipping_threshold_per_sample=15,\n",
    "                     gradient_clipping_with_truncation=True,\n",
    "                     l2_regularization_weight=l2_weight)\n",
    "    trainer = C.Trainer(scores, (loss), [learner], progress_printer)\n",
    "    \n",
    "    train_data_title,train_data_label = train_data\n",
    "    batches = batch_iter(list(zip(train_data_title,train_data_label)), batch_size, num_epochs)\n",
    "\n",
    "    # training loop\n",
    "    count = 0\n",
    "    t = time.time()\n",
    "    for batch in batches:\n",
    "        count += 1\n",
    "        batch_data_title,batch_data_label = zip(*batch)\n",
    "        batch_data_title = list(batch_data_title)\n",
    "        #print(type(batch_data_title),type(batch_data_title[0]),batch_data_title[0])\n",
    "        trainer.train_minibatch({input_xt: np.array(batch_data_title), input_y: np.array(batch_data_label)})\n",
    "        if count%1000== 0:\n",
    "            print(count,time.time()-t)\n",
    "            t=time.time()\n",
    "            acc1=test(batch_size,model,test_data)\n",
    "            #acc2=test(batch_size,model,test_data_editor)\n",
    "            \n",
    "            # save model\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #model.save('./model/{}/{}_acc1{:.3f}_acc2{:.3f}.dnn'.format(suffix,tag,acc1,acc2))\n",
    "    \n",
    "\n",
    "    # save model\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite(Tensor[53]) -> Tensor[1,900]\n",
      "[Output('hidden', [#], [19]), Output('Block3120_Output_0', [#], [1 x 900]), Output('Block3095_Output_0', [#], [1 x 900]), Output('Block2663_Output_0', [#], [1 x 900]), Output('Block2455_Output_0', [#], [1 x 900]), Output('Block2343_Output_0', [#], [1 x 900]), Output('Block2295_Output_0', [#], [1 x 900]), Output('Splice1956_Output_0', [#], [1 x 900]), Output('Slice1953_Output_0', [#], [1 x 300]), Output('embed_1', [#], [53 x 300]), Output('OneHotOp5_Output_0', [#], [53 x 56178]), Output('ReLU60_Output_0', [#], [300]), Output('Plus57_Output_0', [#], [300]), Output('Times51_Output_0', [#], [300]), Output('Squeeze48_Output_0', [#], [300]), Output('Slice45_Output_0', [#], [1 x 300]), Output('Times54_Output_0', [], [300]), Output('ReLU1014_Output_0', [#], [300]), Output('Plus1011_Output_0', [#], [300]), Output('Times1005_Output_0', [#], [300]), Output('Squeeze1002_Output_0', [#], [300]), Output('Slice999_Output_0', [#], [1 x 300]), Output('Times1008_Output_0', [], [300]), Output('Block2279_Output_0', [#], [1 x 900]), Output('Splice1962_Output_0', [#], [1 x 900]), Output('Slice1959_Output_0', [#], [1 x 300]), Output('ReLU78_Output_0', [#], [300]), Output('Plus75_Output_0', [#], [300]), Output('Times69_Output_0', [#], [300]), Output('Squeeze66_Output_0', [#], [300]), Output('Slice63_Output_0', [#], [1 x 300]), Output('Times72_Output_0', [#], [300]), Output('ReLU1032_Output_0', [#], [300]), Output('Plus1029_Output_0', [#], [300]), Output('Times1023_Output_0', [#], [300]), Output('Squeeze1020_Output_0', [#], [300]), Output('Slice1017_Output_0', [#], [1 x 300]), Output('Times1026_Output_0', [#], [300]), Output('Splice1968_Output_0', [#], [1 x 900]), Output('Slice1965_Output_0', [#], [1 x 300]), Output('ReLU96_Output_0', [#], [300]), Output('Plus93_Output_0', [#], [300]), Output('Times87_Output_0', [#], [300]), Output('Squeeze84_Output_0', [#], [300]), Output('Slice81_Output_0', [#], [1 x 300]), Output('Times90_Output_0', [#], [300]), Output('ReLU1050_Output_0', [#], [300]), Output('Plus1047_Output_0', [#], [300]), Output('Times1041_Output_0', [#], [300]), Output('Squeeze1038_Output_0', [#], [300]), Output('Slice1035_Output_0', [#], [1 x 300]), Output('Times1044_Output_0', [#], [300]), Output('Block2327_Output_0', [#], [1 x 900]), Output('Splice1974_Output_0', [#], [1 x 900]), Output('Slice1971_Output_0', [#], [1 x 300]), Output('ReLU114_Output_0', [#], [300]), Output('Plus111_Output_0', [#], [300]), Output('Times105_Output_0', [#], [300]), Output('Squeeze102_Output_0', [#], [300]), Output('Slice99_Output_0', [#], [1 x 300]), Output('Times108_Output_0', [#], [300]), Output('ReLU1068_Output_0', [#], [300]), Output('Plus1065_Output_0', [#], [300]), Output('Times1059_Output_0', [#], [300]), Output('Squeeze1056_Output_0', [#], [300]), Output('Slice1053_Output_0', [#], [1 x 300]), Output('Times1062_Output_0', [#], [300]), Output('Block2311_Output_0', [#], [1 x 900]), Output('Splice1980_Output_0', [#], [1 x 900]), Output('Slice1977_Output_0', [#], [1 x 300]), Output('ReLU132_Output_0', [#], [300]), Output('Plus129_Output_0', [#], [300]), Output('Times123_Output_0', [#], [300]), Output('Squeeze120_Output_0', [#], [300]), Output('Slice117_Output_0', [#], [1 x 300]), Output('Times126_Output_0', [#], [300]), Output('ReLU1086_Output_0', [#], [300]), Output('Plus1083_Output_0', [#], [300]), Output('Times1077_Output_0', [#], [300]), Output('Squeeze1074_Output_0', [#], [300]), Output('Slice1071_Output_0', [#], [1 x 300]), Output('Times1080_Output_0', [#], [300]), Output('Splice1986_Output_0', [#], [1 x 900]), Output('Slice1983_Output_0', [#], [1 x 300]), Output('ReLU150_Output_0', [#], [300]), Output('Plus147_Output_0', [#], [300]), Output('Times141_Output_0', [#], [300]), Output('Squeeze138_Output_0', [#], [300]), Output('Slice135_Output_0', [#], [1 x 300]), Output('Times144_Output_0', [#], [300]), Output('ReLU1104_Output_0', [#], [300]), Output('Plus1101_Output_0', [#], [300]), Output('Times1095_Output_0', [#], [300]), Output('Squeeze1092_Output_0', [#], [300]), Output('Slice1089_Output_0', [#], [1 x 300]), Output('Times1098_Output_0', [#], [300]), Output('Block2439_Output_0', [#], [1 x 900]), Output('Block2375_Output_0', [#], [1 x 900]), Output('Splice1992_Output_0', [#], [1 x 900]), Output('Slice1989_Output_0', [#], [1 x 300]), Output('ReLU168_Output_0', [#], [300]), Output('Plus165_Output_0', [#], [300]), Output('Times159_Output_0', [#], [300]), Output('Squeeze156_Output_0', [#], [300]), Output('Slice153_Output_0', [#], [1 x 300]), Output('Times162_Output_0', [#], [300]), Output('ReLU1122_Output_0', [#], [300]), Output('Plus1119_Output_0', [#], [300]), Output('Times1113_Output_0', [#], [300]), Output('Squeeze1110_Output_0', [#], [300]), Output('Slice1107_Output_0', [#], [1 x 300]), Output('Times1116_Output_0', [#], [300]), Output('Block2359_Output_0', [#], [1 x 900]), Output('Splice1998_Output_0', [#], [1 x 900]), Output('Slice1995_Output_0', [#], [1 x 300]), Output('ReLU186_Output_0', [#], [300]), Output('Plus183_Output_0', [#], [300]), Output('Times177_Output_0', [#], [300]), Output('Squeeze174_Output_0', [#], [300]), Output('Slice171_Output_0', [#], [1 x 300]), Output('Times180_Output_0', [#], [300]), Output('ReLU1140_Output_0', [#], [300]), Output('Plus1137_Output_0', [#], [300]), Output('Times1131_Output_0', [#], [300]), Output('Squeeze1128_Output_0', [#], [300]), Output('Slice1125_Output_0', [#], [1 x 300]), Output('Times1134_Output_0', [#], [300]), Output('Splice2004_Output_0', [#], [1 x 900]), Output('Slice2001_Output_0', [#], [1 x 300]), Output('ReLU204_Output_0', [#], [300]), Output('Plus201_Output_0', [#], [300]), Output('Times195_Output_0', [#], [300]), Output('Squeeze192_Output_0', [#], [300]), Output('Slice189_Output_0', [#], [1 x 300]), Output('Times198_Output_0', [#], [300]), Output('ReLU1158_Output_0', [#], [300]), Output('Plus1155_Output_0', [#], [300]), Output('Times1149_Output_0', [#], [300]), Output('Squeeze1146_Output_0', [#], [300]), Output('Slice1143_Output_0', [#], [1 x 300]), Output('Times1152_Output_0', [#], [300]), Output('Block2423_Output_0', [#], [1 x 900]), Output('Block2391_Output_0', [#], [1 x 900]), Output('Splice2010_Output_0', [#], [1 x 900]), Output('Slice2007_Output_0', [#], [1 x 300]), Output('ReLU222_Output_0', [#], [300]), Output('Plus219_Output_0', [#], [300]), Output('Times213_Output_0', [#], [300]), Output('Squeeze210_Output_0', [#], [300]), Output('Slice207_Output_0', [#], [1 x 300]), Output('Times216_Output_0', [#], [300]), Output('ReLU1176_Output_0', [#], [300]), Output('Plus1173_Output_0', [#], [300]), Output('Times1167_Output_0', [#], [300]), Output('Squeeze1164_Output_0', [#], [300]), Output('Slice1161_Output_0', [#], [1 x 300]), Output('Times1170_Output_0', [#], [300]), Output('Splice2016_Output_0', [#], [1 x 900]), Output('Slice2013_Output_0', [#], [1 x 300]), Output('ReLU240_Output_0', [#], [300]), Output('Plus237_Output_0', [#], [300]), Output('Times231_Output_0', [#], [300]), Output('Squeeze228_Output_0', [#], [300]), Output('Slice225_Output_0', [#], [1 x 300]), Output('Times234_Output_0', [#], [300]), Output('ReLU1194_Output_0', [#], [300]), Output('Plus1191_Output_0', [#], [300]), Output('Times1185_Output_0', [#], [300]), Output('Squeeze1182_Output_0', [#], [300]), Output('Slice1179_Output_0', [#], [1 x 300]), Output('Times1188_Output_0', [#], [300]), Output('Block2407_Output_0', [#], [1 x 900]), Output('Splice2022_Output_0', [#], [1 x 900]), Output('Slice2019_Output_0', [#], [1 x 300]), Output('ReLU258_Output_0', [#], [300]), Output('Plus255_Output_0', [#], [300]), Output('Times249_Output_0', [#], [300]), Output('Squeeze246_Output_0', [#], [300]), Output('Slice243_Output_0', [#], [1 x 300]), Output('Times252_Output_0', [#], [300]), Output('ReLU1212_Output_0', [#], [300]), Output('Plus1209_Output_0', [#], [300]), Output('Times1203_Output_0', [#], [300]), Output('Squeeze1200_Output_0', [#], [300]), Output('Slice1197_Output_0', [#], [1 x 300]), Output('Times1206_Output_0', [#], [300]), Output('Splice2028_Output_0', [#], [1 x 900]), Output('Slice2025_Output_0', [#], [1 x 300]), Output('ReLU276_Output_0', [#], [300]), Output('Plus273_Output_0', [#], [300]), Output('Times267_Output_0', [#], [300]), Output('Squeeze264_Output_0', [#], [300]), Output('Slice261_Output_0', [#], [1 x 300]), Output('Times270_Output_0', [#], [300]), Output('ReLU1230_Output_0', [#], [300]), Output('Plus1227_Output_0', [#], [300]), Output('Times1221_Output_0', [#], [300]), Output('Squeeze1218_Output_0', [#], [300]), Output('Slice1215_Output_0', [#], [1 x 300]), Output('Times1224_Output_0', [#], [300]), Output('Block2647_Output_0', [#], [1 x 900]), Output('Block2535_Output_0', [#], [1 x 900]), Output('Block2487_Output_0', [#], [1 x 900]), Output('Splice2034_Output_0', [#], [1 x 900]), Output('Slice2031_Output_0', [#], [1 x 300]), Output('ReLU294_Output_0', [#], [300]), Output('Plus291_Output_0', [#], [300]), Output('Times285_Output_0', [#], [300]), Output('Squeeze282_Output_0', [#], [300]), Output('Slice279_Output_0', [#], [1 x 300]), Output('Times288_Output_0', [#], [300]), Output('ReLU1248_Output_0', [#], [300]), Output('Plus1245_Output_0', [#], [300]), Output('Times1239_Output_0', [#], [300]), Output('Squeeze1236_Output_0', [#], [300]), Output('Slice1233_Output_0', [#], [1 x 300]), Output('Times1242_Output_0', [#], [300]), Output('Block2471_Output_0', [#], [1 x 900]), Output('Splice2040_Output_0', [#], [1 x 900]), Output('Slice2037_Output_0', [#], [1 x 300]), Output('ReLU312_Output_0', [#], [300]), Output('Plus309_Output_0', [#], [300]), Output('Times303_Output_0', [#], [300]), Output('Squeeze300_Output_0', [#], [300]), Output('Slice297_Output_0', [#], [1 x 300]), Output('Times306_Output_0', [#], [300]), Output('ReLU1266_Output_0', [#], [300]), Output('Plus1263_Output_0', [#], [300]), Output('Times1257_Output_0', [#], [300]), Output('Squeeze1254_Output_0', [#], [300]), Output('Slice1251_Output_0', [#], [1 x 300]), Output('Times1260_Output_0', [#], [300]), Output('Splice2046_Output_0', [#], [1 x 900]), Output('Slice2043_Output_0', [#], [1 x 300]), Output('ReLU330_Output_0', [#], [300]), Output('Plus327_Output_0', [#], [300]), Output('Times321_Output_0', [#], [300]), Output('Squeeze318_Output_0', [#], [300]), Output('Slice315_Output_0', [#], [1 x 300]), Output('Times324_Output_0', [#], [300]), Output('ReLU1284_Output_0', [#], [300]), Output('Plus1281_Output_0', [#], [300]), Output('Times1275_Output_0', [#], [300]), Output('Squeeze1272_Output_0', [#], [300]), Output('Slice1269_Output_0', [#], [1 x 300]), Output('Times1278_Output_0', [#], [300]), Output('Block2519_Output_0', [#], [1 x 900]), Output('Splice2052_Output_0', [#], [1 x 900]), Output('Slice2049_Output_0', [#], [1 x 300]), Output('ReLU348_Output_0', [#], [300]), Output('Plus345_Output_0', [#], [300]), Output('Times339_Output_0', [#], [300]), Output('Squeeze336_Output_0', [#], [300]), Output('Slice333_Output_0', [#], [1 x 300]), Output('Times342_Output_0', [#], [300]), Output('ReLU1302_Output_0', [#], [300]), Output('Plus1299_Output_0', [#], [300]), Output('Times1293_Output_0', [#], [300]), Output('Squeeze1290_Output_0', [#], [300]), Output('Slice1287_Output_0', [#], [1 x 300]), Output('Times1296_Output_0', [#], [300]), Output('Block2503_Output_0', [#], [1 x 900]), Output('Splice2058_Output_0', [#], [1 x 900]), Output('Slice2055_Output_0', [#], [1 x 300]), Output('ReLU366_Output_0', [#], [300]), Output('Plus363_Output_0', [#], [300]), Output('Times357_Output_0', [#], [300]), Output('Squeeze354_Output_0', [#], [300]), Output('Slice351_Output_0', [#], [1 x 300]), Output('Times360_Output_0', [#], [300]), Output('ReLU1320_Output_0', [#], [300]), Output('Plus1317_Output_0', [#], [300]), Output('Times1311_Output_0', [#], [300]), Output('Squeeze1308_Output_0', [#], [300]), Output('Slice1305_Output_0', [#], [1 x 300]), Output('Times1314_Output_0', [#], [300]), Output('Splice2064_Output_0', [#], [1 x 900]), Output('Slice2061_Output_0', [#], [1 x 300]), Output('ReLU384_Output_0', [#], [300]), Output('Plus381_Output_0', [#], [300]), Output('Times375_Output_0', [#], [300]), Output('Squeeze372_Output_0', [#], [300]), Output('Slice369_Output_0', [#], [1 x 300]), Output('Times378_Output_0', [#], [300]), Output('ReLU1338_Output_0', [#], [300]), Output('Plus1335_Output_0', [#], [300]), Output('Times1329_Output_0', [#], [300]), Output('Squeeze1326_Output_0', [#], [300]), Output('Slice1323_Output_0', [#], [1 x 300]), Output('Times1332_Output_0', [#], [300]), Output('Block2631_Output_0', [#], [1 x 900]), Output('Block2567_Output_0', [#], [1 x 900]), Output('Splice2070_Output_0', [#], [1 x 900]), Output('Slice2067_Output_0', [#], [1 x 300]), Output('ReLU402_Output_0', [#], [300]), Output('Plus399_Output_0', [#], [300]), Output('Times393_Output_0', [#], [300]), Output('Squeeze390_Output_0', [#], [300]), Output('Slice387_Output_0', [#], [1 x 300]), Output('Times396_Output_0', [#], [300]), Output('ReLU1356_Output_0', [#], [300]), Output('Plus1353_Output_0', [#], [300]), Output('Times1347_Output_0', [#], [300]), Output('Squeeze1344_Output_0', [#], [300]), Output('Slice1341_Output_0', [#], [1 x 300]), Output('Times1350_Output_0', [#], [300]), Output('Block2551_Output_0', [#], [1 x 900]), Output('Splice2076_Output_0', [#], [1 x 900]), Output('Slice2073_Output_0', [#], [1 x 300]), Output('ReLU420_Output_0', [#], [300]), Output('Plus417_Output_0', [#], [300]), Output('Times411_Output_0', [#], [300]), Output('Squeeze408_Output_0', [#], [300]), Output('Slice405_Output_0', [#], [1 x 300]), Output('Times414_Output_0', [#], [300]), Output('ReLU1374_Output_0', [#], [300]), Output('Plus1371_Output_0', [#], [300]), Output('Times1365_Output_0', [#], [300]), Output('Squeeze1362_Output_0', [#], [300]), Output('Slice1359_Output_0', [#], [1 x 300]), Output('Times1368_Output_0', [#], [300]), Output('Splice2082_Output_0', [#], [1 x 900]), Output('Slice2079_Output_0', [#], [1 x 300]), Output('ReLU438_Output_0', [#], [300]), Output('Plus435_Output_0', [#], [300]), Output('Times429_Output_0', [#], [300]), Output('Squeeze426_Output_0', [#], [300]), Output('Slice423_Output_0', [#], [1 x 300]), Output('Times432_Output_0', [#], [300]), Output('ReLU1392_Output_0', [#], [300]), Output('Plus1389_Output_0', [#], [300]), Output('Times1383_Output_0', [#], [300]), Output('Squeeze1380_Output_0', [#], [300]), Output('Slice1377_Output_0', [#], [1 x 300]), Output('Times1386_Output_0', [#], [300]), Output('Block2615_Output_0', [#], [1 x 900]), Output('Block2583_Output_0', [#], [1 x 900]), Output('Splice2088_Output_0', [#], [1 x 900]), Output('Slice2085_Output_0', [#], [1 x 300]), Output('ReLU456_Output_0', [#], [300]), Output('Plus453_Output_0', [#], [300]), Output('Times447_Output_0', [#], [300]), Output('Squeeze444_Output_0', [#], [300]), Output('Slice441_Output_0', [#], [1 x 300]), Output('Times450_Output_0', [#], [300]), Output('ReLU1410_Output_0', [#], [300]), Output('Plus1407_Output_0', [#], [300]), Output('Times1401_Output_0', [#], [300]), Output('Squeeze1398_Output_0', [#], [300]), Output('Slice1395_Output_0', [#], [1 x 300]), Output('Times1404_Output_0', [#], [300]), Output('Splice2094_Output_0', [#], [1 x 900]), Output('Slice2091_Output_0', [#], [1 x 300]), Output('ReLU474_Output_0', [#], [300]), Output('Plus471_Output_0', [#], [300]), Output('Times465_Output_0', [#], [300]), Output('Squeeze462_Output_0', [#], [300]), Output('Slice459_Output_0', [#], [1 x 300]), Output('Times468_Output_0', [#], [300]), Output('ReLU1428_Output_0', [#], [300]), Output('Plus1425_Output_0', [#], [300]), Output('Times1419_Output_0', [#], [300]), Output('Squeeze1416_Output_0', [#], [300]), Output('Slice1413_Output_0', [#], [1 x 300]), Output('Times1422_Output_0', [#], [300]), Output('Block2599_Output_0', [#], [1 x 900]), Output('Splice2100_Output_0', [#], [1 x 900]), Output('Slice2097_Output_0', [#], [1 x 300]), Output('ReLU492_Output_0', [#], [300]), Output('Plus489_Output_0', [#], [300]), Output('Times483_Output_0', [#], [300]), Output('Squeeze480_Output_0', [#], [300]), Output('Slice477_Output_0', [#], [1 x 300]), Output('Times486_Output_0', [#], [300]), Output('ReLU1446_Output_0', [#], [300]), Output('Plus1443_Output_0', [#], [300]), Output('Times1437_Output_0', [#], [300]), Output('Squeeze1434_Output_0', [#], [300]), Output('Slice1431_Output_0', [#], [1 x 300]), Output('Times1440_Output_0', [#], [300]), Output('Splice2106_Output_0', [#], [1 x 900]), Output('Slice2103_Output_0', [#], [1 x 300]), Output('ReLU510_Output_0', [#], [300]), Output('Plus507_Output_0', [#], [300]), Output('Times501_Output_0', [#], [300]), Output('Squeeze498_Output_0', [#], [300]), Output('Slice495_Output_0', [#], [1 x 300]), Output('Times504_Output_0', [#], [300]), Output('ReLU1464_Output_0', [#], [300]), Output('Plus1461_Output_0', [#], [300]), Output('Times1455_Output_0', [#], [300]), Output('Squeeze1452_Output_0', [#], [300]), Output('Slice1449_Output_0', [#], [1 x 300]), Output('Times1458_Output_0', [#], [300]), Output('Block3079_Output_0', [#], [1 x 900]), Output('Block2855_Output_0', [#], [1 x 900]), Output('Block2743_Output_0', [#], [1 x 900]), Output('Block2695_Output_0', [#], [1 x 900]), Output('Splice2112_Output_0', [#], [1 x 900]), Output('Slice2109_Output_0', [#], [1 x 300]), Output('ReLU528_Output_0', [#], [300]), Output('Plus525_Output_0', [#], [300]), Output('Times519_Output_0', [#], [300]), Output('Squeeze516_Output_0', [#], [300]), Output('Slice513_Output_0', [#], [1 x 300]), Output('Times522_Output_0', [#], [300]), Output('ReLU1482_Output_0', [#], [300]), Output('Plus1479_Output_0', [#], [300]), Output('Times1473_Output_0', [#], [300]), Output('Squeeze1470_Output_0', [#], [300]), Output('Slice1467_Output_0', [#], [1 x 300]), Output('Times1476_Output_0', [#], [300]), Output('Block2679_Output_0', [#], [1 x 900]), Output('Splice2118_Output_0', [#], [1 x 900]), Output('Slice2115_Output_0', [#], [1 x 300]), Output('ReLU546_Output_0', [#], [300]), Output('Plus543_Output_0', [#], [300]), Output('Times537_Output_0', [#], [300]), Output('Squeeze534_Output_0', [#], [300]), Output('Slice531_Output_0', [#], [1 x 300]), Output('Times540_Output_0', [#], [300]), Output('ReLU1500_Output_0', [#], [300]), Output('Plus1497_Output_0', [#], [300]), Output('Times1491_Output_0', [#], [300]), Output('Squeeze1488_Output_0', [#], [300]), Output('Slice1485_Output_0', [#], [1 x 300]), Output('Times1494_Output_0', [#], [300]), Output('Splice2124_Output_0', [#], [1 x 900]), Output('Slice2121_Output_0', [#], [1 x 300]), Output('ReLU564_Output_0', [#], [300]), Output('Plus561_Output_0', [#], [300]), Output('Times555_Output_0', [#], [300]), Output('Squeeze552_Output_0', [#], [300]), Output('Slice549_Output_0', [#], [1 x 300]), Output('Times558_Output_0', [#], [300]), Output('ReLU1518_Output_0', [#], [300]), Output('Plus1515_Output_0', [#], [300]), Output('Times1509_Output_0', [#], [300]), Output('Squeeze1506_Output_0', [#], [300]), Output('Slice1503_Output_0', [#], [1 x 300]), Output('Times1512_Output_0', [#], [300]), Output('Block2727_Output_0', [#], [1 x 900]), Output('Splice2130_Output_0', [#], [1 x 900]), Output('Slice2127_Output_0', [#], [1 x 300]), Output('ReLU582_Output_0', [#], [300]), Output('Plus579_Output_0', [#], [300]), Output('Times573_Output_0', [#], [300]), Output('Squeeze570_Output_0', [#], [300]), Output('Slice567_Output_0', [#], [1 x 300]), Output('Times576_Output_0', [#], [300]), Output('ReLU1536_Output_0', [#], [300]), Output('Plus1533_Output_0', [#], [300]), Output('Times1527_Output_0', [#], [300]), Output('Squeeze1524_Output_0', [#], [300]), Output('Slice1521_Output_0', [#], [1 x 300]), Output('Times1530_Output_0', [#], [300]), Output('Block2711_Output_0', [#], [1 x 900]), Output('Splice2136_Output_0', [#], [1 x 900]), Output('Slice2133_Output_0', [#], [1 x 300]), Output('ReLU600_Output_0', [#], [300]), Output('Plus597_Output_0', [#], [300]), Output('Times591_Output_0', [#], [300]), Output('Squeeze588_Output_0', [#], [300]), Output('Slice585_Output_0', [#], [1 x 300]), Output('Times594_Output_0', [#], [300]), Output('ReLU1554_Output_0', [#], [300]), Output('Plus1551_Output_0', [#], [300]), Output('Times1545_Output_0', [#], [300]), Output('Squeeze1542_Output_0', [#], [300]), Output('Slice1539_Output_0', [#], [1 x 300]), Output('Times1548_Output_0', [#], [300]), Output('Splice2142_Output_0', [#], [1 x 900]), Output('Slice2139_Output_0', [#], [1 x 300]), Output('ReLU618_Output_0', [#], [300]), Output('Plus615_Output_0', [#], [300]), Output('Times609_Output_0', [#], [300]), Output('Squeeze606_Output_0', [#], [300]), Output('Slice603_Output_0', [#], [1 x 300]), Output('Times612_Output_0', [#], [300]), Output('ReLU1572_Output_0', [#], [300]), Output('Plus1569_Output_0', [#], [300]), Output('Times1563_Output_0', [#], [300]), Output('Squeeze1560_Output_0', [#], [300]), Output('Slice1557_Output_0', [#], [1 x 300]), Output('Times1566_Output_0', [#], [300]), Output('Block2839_Output_0', [#], [1 x 900]), Output('Block2775_Output_0', [#], [1 x 900]), Output('Splice2148_Output_0', [#], [1 x 900]), Output('Slice2145_Output_0', [#], [1 x 300]), Output('ReLU636_Output_0', [#], [300]), Output('Plus633_Output_0', [#], [300]), Output('Times627_Output_0', [#], [300]), Output('Squeeze624_Output_0', [#], [300]), Output('Slice621_Output_0', [#], [1 x 300]), Output('Times630_Output_0', [#], [300]), Output('ReLU1590_Output_0', [#], [300]), Output('Plus1587_Output_0', [#], [300]), Output('Times1581_Output_0', [#], [300]), Output('Squeeze1578_Output_0', [#], [300]), Output('Slice1575_Output_0', [#], [1 x 300]), Output('Times1584_Output_0', [#], [300]), Output('Block2759_Output_0', [#], [1 x 900]), Output('Splice2154_Output_0', [#], [1 x 900]), Output('Slice2151_Output_0', [#], [1 x 300]), Output('ReLU654_Output_0', [#], [300]), Output('Plus651_Output_0', [#], [300]), Output('Times645_Output_0', [#], [300]), Output('Squeeze642_Output_0', [#], [300]), Output('Slice639_Output_0', [#], [1 x 300]), Output('Times648_Output_0', [#], [300]), Output('ReLU1608_Output_0', [#], [300]), Output('Plus1605_Output_0', [#], [300]), Output('Times1599_Output_0', [#], [300]), Output('Squeeze1596_Output_0', [#], [300]), Output('Slice1593_Output_0', [#], [1 x 300]), Output('Times1602_Output_0', [#], [300]), Output('Splice2160_Output_0', [#], [1 x 900]), Output('Slice2157_Output_0', [#], [1 x 300]), Output('ReLU672_Output_0', [#], [300]), Output('Plus669_Output_0', [#], [300]), Output('Times663_Output_0', [#], [300]), Output('Squeeze660_Output_0', [#], [300]), Output('Slice657_Output_0', [#], [1 x 300]), Output('Times666_Output_0', [#], [300]), Output('ReLU1626_Output_0', [#], [300]), Output('Plus1623_Output_0', [#], [300]), Output('Times1617_Output_0', [#], [300]), Output('Squeeze1614_Output_0', [#], [300]), Output('Slice1611_Output_0', [#], [1 x 300]), Output('Times1620_Output_0', [#], [300]), Output('Block2823_Output_0', [#], [1 x 900]), Output('Block2791_Output_0', [#], [1 x 900]), Output('Splice2166_Output_0', [#], [1 x 900]), Output('Slice2163_Output_0', [#], [1 x 300]), Output('ReLU690_Output_0', [#], [300]), Output('Plus687_Output_0', [#], [300]), Output('Times681_Output_0', [#], [300]), Output('Squeeze678_Output_0', [#], [300]), Output('Slice675_Output_0', [#], [1 x 300]), Output('Times684_Output_0', [#], [300]), Output('ReLU1644_Output_0', [#], [300]), Output('Plus1641_Output_0', [#], [300]), Output('Times1635_Output_0', [#], [300]), Output('Squeeze1632_Output_0', [#], [300]), Output('Slice1629_Output_0', [#], [1 x 300]), Output('Times1638_Output_0', [#], [300]), Output('Splice2172_Output_0', [#], [1 x 900]), Output('Slice2169_Output_0', [#], [1 x 300]), Output('ReLU708_Output_0', [#], [300]), Output('Plus705_Output_0', [#], [300]), Output('Times699_Output_0', [#], [300]), Output('Squeeze696_Output_0', [#], [300]), Output('Slice693_Output_0', [#], [1 x 300]), Output('Times702_Output_0', [#], [300]), Output('ReLU1662_Output_0', [#], [300]), Output('Plus1659_Output_0', [#], [300]), Output('Times1653_Output_0', [#], [300]), Output('Squeeze1650_Output_0', [#], [300]), Output('Slice1647_Output_0', [#], [1 x 300]), Output('Times1656_Output_0', [#], [300]), Output('Block2807_Output_0', [#], [1 x 900]), Output('Splice2178_Output_0', [#], [1 x 900]), Output('Slice2175_Output_0', [#], [1 x 300]), Output('ReLU726_Output_0', [#], [300]), Output('Plus723_Output_0', [#], [300]), Output('Times717_Output_0', [#], [300]), Output('Squeeze714_Output_0', [#], [300]), Output('Slice711_Output_0', [#], [1 x 300]), Output('Times720_Output_0', [#], [300]), Output('ReLU1680_Output_0', [#], [300]), Output('Plus1677_Output_0', [#], [300]), Output('Times1671_Output_0', [#], [300]), Output('Squeeze1668_Output_0', [#], [300]), Output('Slice1665_Output_0', [#], [1 x 300]), Output('Times1674_Output_0', [#], [300]), Output('Splice2184_Output_0', [#], [1 x 900]), Output('Slice2181_Output_0', [#], [1 x 300]), Output('ReLU744_Output_0', [#], [300]), Output('Plus741_Output_0', [#], [300]), Output('Times735_Output_0', [#], [300]), Output('Squeeze732_Output_0', [#], [300]), Output('Slice729_Output_0', [#], [1 x 300]), Output('Times738_Output_0', [#], [300]), Output('ReLU1698_Output_0', [#], [300]), Output('Plus1695_Output_0', [#], [300]), Output('Times1689_Output_0', [#], [300]), Output('Squeeze1686_Output_0', [#], [300]), Output('Slice1683_Output_0', [#], [1 x 300]), Output('Times1692_Output_0', [#], [300]), Output('Block3063_Output_0', [#], [1 x 900]), Output('Block2951_Output_0', [#], [1 x 900]), Output('Block2887_Output_0', [#], [1 x 900]), Output('Splice2190_Output_0', [#], [1 x 900]), Output('Slice2187_Output_0', [#], [1 x 300]), Output('ReLU762_Output_0', [#], [300]), Output('Plus759_Output_0', [#], [300]), Output('Times753_Output_0', [#], [300]), Output('Squeeze750_Output_0', [#], [300]), Output('Slice747_Output_0', [#], [1 x 300]), Output('Times756_Output_0', [#], [300]), Output('ReLU1716_Output_0', [#], [300]), Output('Plus1713_Output_0', [#], [300]), Output('Times1707_Output_0', [#], [300]), Output('Squeeze1704_Output_0', [#], [300]), Output('Slice1701_Output_0', [#], [1 x 300]), Output('Times1710_Output_0', [#], [300]), Output('Block2871_Output_0', [#], [1 x 900]), Output('Splice2196_Output_0', [#], [1 x 900]), Output('Slice2193_Output_0', [#], [1 x 300]), Output('ReLU780_Output_0', [#], [300]), Output('Plus777_Output_0', [#], [300]), Output('Times771_Output_0', [#], [300]), Output('Squeeze768_Output_0', [#], [300]), Output('Slice765_Output_0', [#], [1 x 300]), Output('Times774_Output_0', [#], [300]), Output('ReLU1734_Output_0', [#], [300]), Output('Plus1731_Output_0', [#], [300]), Output('Times1725_Output_0', [#], [300]), Output('Squeeze1722_Output_0', [#], [300]), Output('Slice1719_Output_0', [#], [1 x 300]), Output('Times1728_Output_0', [#], [300]), Output('Splice2202_Output_0', [#], [1 x 900]), Output('Slice2199_Output_0', [#], [1 x 300]), Output('ReLU798_Output_0', [#], [300]), Output('Plus795_Output_0', [#], [300]), Output('Times789_Output_0', [#], [300]), Output('Squeeze786_Output_0', [#], [300]), Output('Slice783_Output_0', [#], [1 x 300]), Output('Times792_Output_0', [#], [300]), Output('ReLU1752_Output_0', [#], [300]), Output('Plus1749_Output_0', [#], [300]), Output('Times1743_Output_0', [#], [300]), Output('Squeeze1740_Output_0', [#], [300]), Output('Slice1737_Output_0', [#], [1 x 300]), Output('Times1746_Output_0', [#], [300]), Output('Block2935_Output_0', [#], [1 x 900]), Output('Block2903_Output_0', [#], [1 x 900]), Output('Splice2208_Output_0', [#], [1 x 900]), Output('Slice2205_Output_0', [#], [1 x 300]), Output('ReLU816_Output_0', [#], [300]), Output('Plus813_Output_0', [#], [300]), Output('Times807_Output_0', [#], [300]), Output('Squeeze804_Output_0', [#], [300]), Output('Slice801_Output_0', [#], [1 x 300]), Output('Times810_Output_0', [#], [300]), Output('ReLU1770_Output_0', [#], [300]), Output('Plus1767_Output_0', [#], [300]), Output('Times1761_Output_0', [#], [300]), Output('Squeeze1758_Output_0', [#], [300]), Output('Slice1755_Output_0', [#], [1 x 300]), Output('Times1764_Output_0', [#], [300]), Output('Splice2214_Output_0', [#], [1 x 900]), Output('Slice2211_Output_0', [#], [1 x 300]), Output('ReLU834_Output_0', [#], [300]), Output('Plus831_Output_0', [#], [300]), Output('Times825_Output_0', [#], [300]), Output('Squeeze822_Output_0', [#], [300]), Output('Slice819_Output_0', [#], [1 x 300]), Output('Times828_Output_0', [#], [300]), Output('ReLU1788_Output_0', [#], [300]), Output('Plus1785_Output_0', [#], [300]), Output('Times1779_Output_0', [#], [300]), Output('Squeeze1776_Output_0', [#], [300]), Output('Slice1773_Output_0', [#], [1 x 300]), Output('Times1782_Output_0', [#], [300]), Output('Block2919_Output_0', [#], [1 x 900]), Output('Splice2220_Output_0', [#], [1 x 900]), Output('Slice2217_Output_0', [#], [1 x 300]), Output('ReLU852_Output_0', [#], [300]), Output('Plus849_Output_0', [#], [300]), Output('Times843_Output_0', [#], [300]), Output('Squeeze840_Output_0', [#], [300]), Output('Slice837_Output_0', [#], [1 x 300]), Output('Times846_Output_0', [#], [300]), Output('ReLU1806_Output_0', [#], [300]), Output('Plus1803_Output_0', [#], [300]), Output('Times1797_Output_0', [#], [300]), Output('Squeeze1794_Output_0', [#], [300]), Output('Slice1791_Output_0', [#], [1 x 300]), Output('Times1800_Output_0', [#], [300]), Output('Splice2226_Output_0', [#], [1 x 900]), Output('Slice2223_Output_0', [#], [1 x 300]), Output('ReLU870_Output_0', [#], [300]), Output('Plus867_Output_0', [#], [300]), Output('Times861_Output_0', [#], [300]), Output('Squeeze858_Output_0', [#], [300]), Output('Slice855_Output_0', [#], [1 x 300]), Output('Times864_Output_0', [#], [300]), Output('ReLU1824_Output_0', [#], [300]), Output('Plus1821_Output_0', [#], [300]), Output('Times1815_Output_0', [#], [300]), Output('Squeeze1812_Output_0', [#], [300]), Output('Slice1809_Output_0', [#], [1 x 300]), Output('Times1818_Output_0', [#], [300]), Output('Block3047_Output_0', [#], [1 x 900]), Output('Block2983_Output_0', [#], [1 x 900]), Output('Splice2232_Output_0', [#], [1 x 900]), Output('Slice2229_Output_0', [#], [1 x 300]), Output('ReLU888_Output_0', [#], [300]), Output('Plus885_Output_0', [#], [300]), Output('Times879_Output_0', [#], [300]), Output('Squeeze876_Output_0', [#], [300]), Output('Slice873_Output_0', [#], [1 x 300]), Output('Times882_Output_0', [#], [300]), Output('ReLU1842_Output_0', [#], [300]), Output('Plus1839_Output_0', [#], [300]), Output('Times1833_Output_0', [#], [300]), Output('Squeeze1830_Output_0', [#], [300]), Output('Slice1827_Output_0', [#], [1 x 300]), Output('Times1836_Output_0', [#], [300]), Output('Block2967_Output_0', [#], [1 x 900]), Output('Splice2238_Output_0', [#], [1 x 900]), Output('Slice2235_Output_0', [#], [1 x 300]), Output('ReLU906_Output_0', [#], [300]), Output('Plus903_Output_0', [#], [300]), Output('Times897_Output_0', [#], [300]), Output('Squeeze894_Output_0', [#], [300]), Output('Slice891_Output_0', [#], [1 x 300]), Output('Times900_Output_0', [#], [300]), Output('ReLU1860_Output_0', [#], [300]), Output('Plus1857_Output_0', [#], [300]), Output('Times1851_Output_0', [#], [300]), Output('Squeeze1848_Output_0', [#], [300]), Output('Slice1845_Output_0', [#], [1 x 300]), Output('Times1854_Output_0', [#], [300]), Output('Splice2244_Output_0', [#], [1 x 900]), Output('Slice2241_Output_0', [#], [1 x 300]), Output('ReLU924_Output_0', [#], [300]), Output('Plus921_Output_0', [#], [300]), Output('Times915_Output_0', [#], [300]), Output('Squeeze912_Output_0', [#], [300]), Output('Slice909_Output_0', [#], [1 x 300]), Output('Times918_Output_0', [#], [300]), Output('ReLU1878_Output_0', [#], [300]), Output('Plus1875_Output_0', [#], [300]), Output('Times1869_Output_0', [#], [300]), Output('Squeeze1866_Output_0', [#], [300]), Output('Slice1863_Output_0', [#], [1 x 300]), Output('Times1872_Output_0', [#], [300]), Output('Block3031_Output_0', [#], [1 x 900]), Output('Block2999_Output_0', [#], [1 x 900]), Output('Splice2250_Output_0', [#], [1 x 900]), Output('Slice2247_Output_0', [#], [1 x 300]), Output('ReLU942_Output_0', [#], [300]), Output('Plus939_Output_0', [#], [300]), Output('Times933_Output_0', [#], [300]), Output('Squeeze930_Output_0', [#], [300]), Output('Slice927_Output_0', [#], [1 x 300]), Output('Times936_Output_0', [#], [300]), Output('ReLU1896_Output_0', [#], [300]), Output('Plus1893_Output_0', [#], [300]), Output('Times1887_Output_0', [#], [300]), Output('Squeeze1884_Output_0', [#], [300]), Output('Slice1881_Output_0', [#], [1 x 300]), Output('Times1890_Output_0', [#], [300]), Output('Splice2256_Output_0', [#], [1 x 900]), Output('Slice2253_Output_0', [#], [1 x 300]), Output('ReLU960_Output_0', [#], [300]), Output('Plus957_Output_0', [#], [300]), Output('Times951_Output_0', [#], [300]), Output('Squeeze948_Output_0', [#], [300]), Output('Slice945_Output_0', [#], [1 x 300]), Output('Times954_Output_0', [#], [300]), Output('ReLU1914_Output_0', [#], [300]), Output('Plus1911_Output_0', [#], [300]), Output('Times1905_Output_0', [#], [300]), Output('Squeeze1902_Output_0', [#], [300]), Output('Slice1899_Output_0', [#], [1 x 300]), Output('Times1908_Output_0', [#], [300]), Output('Block3015_Output_0', [#], [1 x 900]), Output('Splice2262_Output_0', [#], [1 x 900]), Output('Slice2259_Output_0', [#], [1 x 300]), Output('ReLU978_Output_0', [#], [300]), Output('Plus975_Output_0', [#], [300]), Output('Times969_Output_0', [#], [300]), Output('Squeeze966_Output_0', [#], [300]), Output('Slice963_Output_0', [#], [1 x 300]), Output('Times972_Output_0', [#], [300]), Output('ReLU1932_Output_0', [#], [300]), Output('Plus1929_Output_0', [#], [300]), Output('Times1923_Output_0', [#], [300]), Output('Squeeze1920_Output_0', [#], [300]), Output('Slice1917_Output_0', [#], [1 x 300]), Output('Times1926_Output_0', [#], [300]), Output('Splice2268_Output_0', [#], [1 x 900]), Output('Slice2265_Output_0', [#], [1 x 300]), Output('ReLU996_Output_0', [#], [300]), Output('Plus993_Output_0', [#], [300]), Output('Times987_Output_0', [#], [300]), Output('Squeeze984_Output_0', [#], [300]), Output('Slice981_Output_0', [#], [1 x 300]), Output('Times990_Output_0', [#], [300]), Output('ReLU1950_Output_0', [#], [300]), Output('Plus1947_Output_0', [#], [300]), Output('Times1941_Output_0', [#], [300]), Output('Squeeze1938_Output_0', [#], [300]), Output('Slice1935_Output_0', [#], [1 x 300]), Output('Times1944_Output_0', [#], [300])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size:  768505 batch_size:  150 num_batches_per_epoch:  5124\n",
      "Learning rate per minibatch: 0.075\n",
      "1000 218.89154291152954\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t-haohu/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/ipykernel_launcher.py:190: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.21441986354661133 Recall:0.45721245622740303 Acc:0.4410796696623755\n",
      "2000 418.47130823135376\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.22791772785680003 Recall:0.4653151945034397 Acc:0.449477775078941\n",
      "3000 412.2785406112671\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23237336537425962 Recall:0.48654128735308033 Acc:0.44986944376973526\n",
      "4000 398.820583820343\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.22685674786609997 Recall:0.49774699044082693 Acc:0.45211622540684965\n",
      "5000 425.7612085342407\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23063491570275987 Recall:0.48158789533650137 Acc:0.45160007286859366\n",
      "6000 418.37432384490967\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.22895529680820667 Recall:0.473562079294015 Acc:0.4475497935389847\n",
      "7000 399.1861381530762\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.2258648189010534 Recall:0.507651194891444 Acc:0.44833920330337623\n",
      "8000 370.546178817749\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23098649548713074 Recall:0.5001086931506101 Acc:0.4514816614039349\n",
      "9000 416.0939280986786\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.2368279237492461 Recall:0.5078857507423913 Acc:0.45640636385717753\n",
      "10000 421.99885749816895\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.2483467681645283 Recall:0.4525535090369194 Acc:0.46263359242166624\n",
      "11000 399.27455163002014\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.2365689436952068 Recall:0.4637314401908278 Acc:0.45278115132377944\n",
      "12000 403.4988126754761\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23174475838430014 Recall:0.46503586573133743 Acc:0.4509928345882924\n",
      "13000 425.8356544971466\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.24130285773899565 Recall:0.4685336843866855 Acc:0.4543872965751761\n",
      "14000 412.2277400493622\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23105878029922766 Recall:0.484114328593074 Acc:0.4551493806169541\n",
      "15000 353.38134002685547\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23206565043693023 Recall:0.5285948210760911 Acc:0.45166079669662373\n",
      "16000 389.883159160614\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.22858207094785055 Recall:0.48834703292821957 Acc:0.4494443769735244\n",
      "17000 415.0071074962616\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23587353748799425 Recall:0.4608314248508196 Acc:0.45180349769249456\n",
      "18000 430.33599519729614\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23947967283404642 Recall:0.4934212582754861 Acc:0.4569893126062667\n",
      "19000 407.1654658317566\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.2510553685827205 Recall:0.4588714204419227 Acc:0.4641941948020403\n",
      "20000 419.45559763908386\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.2494121697480284 Recall:0.46722700504414877 Acc:0.4642336652902599\n",
      "21000 420.17133831977844\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.24070518422087434 Recall:0.4899489542414358 Acc:0.4577392518824387\n",
      "22000 361.77749013900757\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.24121190180550328 Recall:0.4778146052867253 Acc:0.46052647558902116\n",
      "23000 403.3281409740448\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23620151702846004 Recall:0.49332716202458093 Acc:0.4568557201846004\n",
      "24000 416.99276900291443\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23575638188006995 Recall:0.5251332800425746 Acc:0.4562211561816857\n",
      "25000 427.4280753135681\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.24216893538010545 Recall:0.47625368130899753 Acc:0.45441158610638815\n",
      "26000 400.4510040283203\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23855075212092194 Recall:0.4550615644969913 Acc:0.4538802526111246\n",
      "27000 338.5880055427551\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.2329660974979098 Recall:0.5113985383133213 Acc:0.45303315521010445\n",
      "28000 243.50365281105042\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.23373331924976548 Recall:0.48976331844152865 Acc:0.45488523196502306\n",
      "29000 276.15975069999695\n",
      "data_size:  329360 batch_size:  150 num_batches_per_epoch:  2196\n",
      "Precision:0.22686040577890196 Recall:0.511953719036506 Acc:0.44701238766091816\n"
     ]
    }
   ],
   "source": [
    "train(train_data,num_epochs=20,learning_rate=[5e-4*150]*2+[1e-4*150],batch_size = 150,tag = \"RCNN_Embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input('Input233', [#], [10 x 10])\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "Slice(Tensor[10,10]) -> Tensor[1,10]\n",
      "233 Slice(Tensor[10,10]) -> Tensor[1,10]\n"
     ]
    }
   ],
   "source": [
    "import cntk as C\n",
    "a =C.input_variable(shape=(10,10))\n",
    "b =C.input_variable(shape=(10,10))\n",
    "c= C.combine(a,b)\n",
    "print(c[0])\n",
    "for i,x in enumerate(a):\n",
    "    print(x)\n",
    "    if i == 9:\n",
    "        break\n",
    "print(\"233\",a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cntk.layers import *\n",
    "from cntk.layers.typing import *\n",
    "a =C.input_variable(**Sequence[Tensor[1]])\n",
    "b= [[[1],[3],[5]],[[1],[3],[5],[7]]]\n",
    "c = C.plus(a,a)\n",
    "d = C.layers.Fold(C.element_max)(c)\n",
    "w = C.parameter(shape=(1))\n",
    "e = d*w\n",
    "learner = C.adam(parameters=e.parameters,#model.parameters,\n",
    "                     lr=1e-3,\n",
    "                     momentum=0.9,\n",
    "                     gradient_clipping_threshold_per_sample=15,\n",
    "                     gradient_clipping_with_truncation=True,\n",
    "                     l2_regularization_weight=0)\n",
    "trainer = C.Trainer(e, (e), [learner])\n",
    "print(e(b))\n",
    "trainer.train_minibatch({a:b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.,  8.],\n",
       "        [12., 16.]]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = C.input_variable(shape=(2,2))\n",
    "b = C.plus(a,a)\n",
    "d = b+b\n",
    "c = C.element_max(*[a,b,d])\n",
    "c([[[1,2],[3,4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
